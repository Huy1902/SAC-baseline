step: 0 @ episode report: {'average_total_reward': np.float64(0.0), 'reward_variance': np.float64(0.0), 'max_total_reward': np.float64(0.0), 'min_total_reward': np.float64(0.0), 'average_n_step': np.float64(0.0), 'max_n_step': np.float64(0.0), 'min_n_step': np.float64(0.0), 'buffer_size': 2048} @ step loss: {'critic_loss': np.float64(34.41698455810547), 'actor_loss': np.float64(-7.878915786743164), 'alpha_loss': np.float64(0.0), 'alpha': np.float64(0.9997000694274902)}
step: 0 @ episode report: {'average_total_reward': np.float64(0.0), 'reward_variance': np.float64(0.0), 'max_total_reward': np.float64(0.0), 'min_total_reward': np.float64(0.0), 'average_n_step': np.float64(0.0), 'max_n_step': np.float64(0.0), 'min_n_step': np.float64(0.0), 'buffer_size': 2048} @ step loss: {'critic_loss': np.float64(34.58826446533203), 'actor_loss': np.float64(-7.878915786743164), 'alpha_loss': np.float64(0.0), 'alpha': np.float64(0.9997000694274902)}
step: 10 @ episode report: {'average_total_reward': np.float32(0.443), 'reward_variance': np.float32(0.111521006), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 2368} @ step loss: {'critic_loss': np.float64(36.679215049743654), 'actor_loss': np.float64(-7.896495342254639), 'alpha_loss': np.float64(-3.2568187180004315e-05), 'alpha': np.float64(0.9980747163295746)}
step: 20 @ episode report: {'average_total_reward': np.float32(0.688), 'reward_variance': np.float32(0.096375994), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 2688} @ step loss: {'critic_loss': np.float64(35.28452644348145), 'actor_loss': np.float64(-7.92566704750061), 'alpha_loss': np.float64(-0.00011066673396271653), 'alpha': np.float64(0.9950525164604187)}
step: 30 @ episode report: {'average_total_reward': np.float32(0.61), 'reward_variance': np.float32(0.10880002), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.24000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 3008} @ step loss: {'critic_loss': np.float64(32.210001945495605), 'actor_loss': np.float64(-7.958728551864624), 'alpha_loss': np.float64(-0.00020328413593233562), 'alpha': np.float64(0.9919509053230285)}
step: 40 @ episode report: {'average_total_reward': np.float32(0.61099994), 'reward_variance': np.float32(0.12324901), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 3328} @ step loss: {'critic_loss': np.float64(33.44532318115235), 'actor_loss': np.float64(-8.000364923477173), 'alpha_loss': np.float64(-0.00030951613443903626), 'alpha': np.float64(0.9888015627861023)}
step: 50 @ episode report: {'average_total_reward': np.float32(0.55500007), 'reward_variance': np.float32(0.12084502), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.019999996), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 3648} @ step loss: {'critic_loss': np.float64(32.92203330993652), 'actor_loss': np.float64(-8.049730396270752), 'alpha_loss': np.float64(-0.0004711089684860781), 'alpha': np.float64(0.9854975342750549)}
step: 60 @ episode report: {'average_total_reward': np.float32(0.46499997), 'reward_variance': np.float32(0.077685), 'max_total_reward': np.float32(0.8), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 3968} @ step loss: {'critic_loss': np.float64(30.786137962341307), 'actor_loss': np.float64(-8.09465045928955), 'alpha_loss': np.float64(-0.0006373527634423226), 'alpha': np.float64(0.9820299565792083)}
step: 70 @ episode report: {'average_total_reward': np.float32(0.888), 'reward_variance': np.float32(0.026136), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 4288} @ step loss: {'critic_loss': np.float64(30.265057373046876), 'actor_loss': np.float64(-8.143996238708496), 'alpha_loss': np.float64(-0.0008099441765807569), 'alpha': np.float64(0.9784915030002594)}
step: 80 @ episode report: {'average_total_reward': np.float32(0.767), 'reward_variance': np.float32(0.24368103), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 4608} @ step loss: {'critic_loss': np.float64(30.056613159179687), 'actor_loss': np.float64(-8.19615650177002), 'alpha_loss': np.float64(-0.0010590129066258668), 'alpha': np.float64(0.9748640418052673)}
step: 90 @ episode report: {'average_total_reward': np.float32(0.7990001), 'reward_variance': np.float32(0.071289), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 4928} @ step loss: {'critic_loss': np.float64(30.592575073242188), 'actor_loss': np.float64(-8.251662540435792), 'alpha_loss': np.float64(-0.0012799673480913044), 'alpha': np.float64(0.9711582362651825)}
step: 100 @ episode report: {'average_total_reward': np.float32(0.654), 'reward_variance': np.float32(0.11434402), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 5248} @ step loss: {'critic_loss': np.float64(28.00036907196045), 'actor_loss': np.float64(-8.30141716003418), 'alpha_loss': np.float64(-0.001595851848833263), 'alpha': np.float64(0.9673933804035186)}
step: 110 @ episode report: {'average_total_reward': np.float32(0.787), 'reward_variance': np.float32(0.11744101), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 5568} @ step loss: {'critic_loss': np.float64(27.82625045776367), 'actor_loss': np.float64(-8.356389999389648), 'alpha_loss': np.float64(-0.0018105172319337725), 'alpha': np.float64(0.9635948598384857)}
step: 120 @ episode report: {'average_total_reward': np.float32(0.64400005), 'reward_variance': np.float32(0.10218402), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 5888} @ step loss: {'critic_loss': np.float64(26.217049217224123), 'actor_loss': np.float64(-8.417725753784179), 'alpha_loss': np.float64(-0.002080225222744048), 'alpha': np.float64(0.95981724858284)}
step: 130 @ episode report: {'average_total_reward': np.float32(0.83300006), 'reward_variance': np.float32(0.021901), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.5800001), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 6208} @ step loss: {'critic_loss': np.float64(27.46763801574707), 'actor_loss': np.float64(-8.471121025085449), 'alpha_loss': np.float64(-0.002435918245464563), 'alpha': np.float64(0.95601766705513)}
step: 140 @ episode report: {'average_total_reward': np.float32(0.9210001), 'reward_variance': np.float32(0.068849005), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 6528} @ step loss: {'critic_loss': np.float64(28.07151355743408), 'actor_loss': np.float64(-8.544365787506104), 'alpha_loss': np.float64(-0.002616530703380704), 'alpha': np.float64(0.9522561728954315)}
step: 150 @ episode report: {'average_total_reward': np.float32(0.875), 'reward_variance': np.float32(0.15026502), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 6848} @ step loss: {'critic_loss': np.float64(25.815014839172363), 'actor_loss': np.float64(-8.60986909866333), 'alpha_loss': np.float64(-0.0030069834319874644), 'alpha': np.float64(0.9485239505767822)}
step: 160 @ episode report: {'average_total_reward': np.float32(0.866), 'reward_variance': np.float32(0.044044007), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 7168} @ step loss: {'critic_loss': np.float64(25.53603000640869), 'actor_loss': np.float64(-8.676318168640137), 'alpha_loss': np.float64(-0.0032637171680107713), 'alpha': np.float64(0.9447885096073151)}
step: 170 @ episode report: {'average_total_reward': np.float32(0.87600005), 'reward_variance': np.float32(0.078824), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 7488} @ step loss: {'critic_loss': np.float64(24.405842781066895), 'actor_loss': np.float64(-8.740303421020508), 'alpha_loss': np.float64(-0.0034504099981859325), 'alpha': np.float64(0.9410978555679321)}
step: 180 @ episode report: {'average_total_reward': np.float32(0.7990001), 'reward_variance': np.float32(0.06402901), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 7808} @ step loss: {'critic_loss': np.float64(24.015532302856446), 'actor_loss': np.float64(-8.811317729949952), 'alpha_loss': np.float64(-0.0037745164008811116), 'alpha': np.float64(0.9374720811843872)}
step: 190 @ episode report: {'average_total_reward': np.float32(0.844), 'reward_variance': np.float32(0.05614399), 'max_total_reward': np.float32(1.3499999), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 8128} @ step loss: {'critic_loss': np.float64(25.103964614868165), 'actor_loss': np.float64(-8.88077917098999), 'alpha_loss': np.float64(-0.004008908546529711), 'alpha': np.float64(0.9339119493961334)}
step: 200 @ episode report: {'average_total_reward': np.float32(0.623), 'reward_variance': np.float32(0.061961014), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 8448} @ step loss: {'critic_loss': np.float64(23.292094421386718), 'actor_loss': np.float64(-8.958806037902832), 'alpha_loss': np.float64(-0.004438566090539098), 'alpha': np.float64(0.930371779203415)}
step: 210 @ episode report: {'average_total_reward': np.float32(0.79899997), 'reward_variance': np.float32(0.071288995), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 8768} @ step loss: {'critic_loss': np.float64(22.736126136779784), 'actor_loss': np.float64(-9.040855216979981), 'alpha_loss': np.float64(-0.004316397756338119), 'alpha': np.float64(0.926865178346634)}
step: 220 @ episode report: {'average_total_reward': np.float32(0.90900004), 'reward_variance': np.float32(0.20792904), 'max_total_reward': np.float32(1.8000002), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 9088} @ step loss: {'critic_loss': np.float64(23.29459857940674), 'actor_loss': np.float64(-9.119191551208496), 'alpha_loss': np.float64(-0.004516469035297632), 'alpha': np.float64(0.92350252866745)}
step: 230 @ episode report: {'average_total_reward': np.float32(0.68700004), 'reward_variance': np.float32(0.10430101), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 9408} @ step loss: {'critic_loss': np.float64(23.66716060638428), 'actor_loss': np.float64(-9.196896266937255), 'alpha_loss': np.float64(-0.004701381828635931), 'alpha': np.float64(0.9202331900596619)}
step: 240 @ episode report: {'average_total_reward': np.float32(0.844), 'reward_variance': np.float32(0.051304005), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 9728} @ step loss: {'critic_loss': np.float64(22.319344329833985), 'actor_loss': np.float64(-9.284883785247803), 'alpha_loss': np.float64(-0.004742771247401833), 'alpha': np.float64(0.9170451760292053)}
step: 250 @ episode report: {'average_total_reward': np.float32(0.71999997), 'reward_variance': np.float32(0.12177999), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 10048} @ step loss: {'critic_loss': np.float64(22.271242523193358), 'actor_loss': np.float64(-9.383685207366943), 'alpha_loss': np.float64(-0.004915474867448211), 'alpha': np.float64(0.9139457702636719)}
step: 260 @ episode report: {'average_total_reward': np.float32(0.96599996), 'reward_variance': np.float32(0.09664401), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 10368} @ step loss: {'critic_loss': np.float64(21.224069023132323), 'actor_loss': np.float64(-9.4592942237854), 'alpha_loss': np.float64(-0.0050882047042250635), 'alpha': np.float64(0.9109117805957794)}
step: 270 @ episode report: {'average_total_reward': np.float32(0.621), 'reward_variance': np.float32(0.19722906), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 10688} @ step loss: {'critic_loss': np.float64(21.85371627807617), 'actor_loss': np.float64(-9.546521949768067), 'alpha_loss': np.float64(-0.005042443471029401), 'alpha': np.float64(0.9079246342182159)}
step: 280 @ episode report: {'average_total_reward': np.float32(0.732), 'reward_variance': np.float32(0.092196), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 11008} @ step loss: {'critic_loss': np.float64(21.210993766784668), 'actor_loss': np.float64(-9.63485927581787), 'alpha_loss': np.float64(-0.004977488843724132), 'alpha': np.float64(0.9050524950027465)}
step: 290 @ episode report: {'average_total_reward': np.float32(0.94299996), 'reward_variance': np.float32(0.24084096), 'max_total_reward': np.float32(1.9099998), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 11328} @ step loss: {'critic_loss': np.float64(20.92398853302002), 'actor_loss': np.float64(-9.730874252319335), 'alpha_loss': np.float64(-0.00471922536380589), 'alpha': np.float64(0.9023179411888123)}
step: 300 @ episode report: {'average_total_reward': np.float32(0.57799995), 'reward_variance': np.float32(0.071516), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 11648} @ step loss: {'critic_loss': np.float64(20.832806205749513), 'actor_loss': np.float64(-9.8082426071167), 'alpha_loss': np.float64(-0.004724066331982612), 'alpha': np.float64(0.8997341811656951)}
step: 310 @ episode report: {'average_total_reward': np.float32(1.031), 'reward_variance': np.float32(0.17842904), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 11968} @ step loss: {'critic_loss': np.float64(21.73727169036865), 'actor_loss': np.float64(-9.904813957214355), 'alpha_loss': np.float64(-0.004527467954903841), 'alpha': np.float64(0.8972658395767212)}
step: 320 @ episode report: {'average_total_reward': np.float32(0.56600004), 'reward_variance': np.float32(0.083104014), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 12288} @ step loss: {'critic_loss': np.float64(20.697390747070312), 'actor_loss': np.float64(-10.023494625091553), 'alpha_loss': np.float64(-0.004111678688786924), 'alpha': np.float64(0.8949455976486206)}
step: 330 @ episode report: {'average_total_reward': np.float32(0.676), 'reward_variance': np.float32(0.15944402), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(-0.09000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 12608} @ step loss: {'critic_loss': np.float64(20.725777626037598), 'actor_loss': np.float64(-10.115599727630615), 'alpha_loss': np.float64(-0.003828740678727627), 'alpha': np.float64(0.8928390800952911)}
step: 340 @ episode report: {'average_total_reward': np.float32(0.91099995), 'reward_variance': np.float32(0.110009), 'max_total_reward': np.float32(1.47), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 12928} @ step loss: {'critic_loss': np.float64(20.146998786926268), 'actor_loss': np.float64(-10.197346210479736), 'alpha_loss': np.float64(-0.00363186108879745), 'alpha': np.float64(0.8908758282661438)}
step: 350 @ episode report: {'average_total_reward': np.float32(0.62), 'reward_variance': np.float32(0.15882002), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 13248} @ step loss: {'critic_loss': np.float64(20.66427516937256), 'actor_loss': np.float64(-10.305621337890624), 'alpha_loss': np.float64(-0.0034678409807384013), 'alpha': np.float64(0.8890781402587891)}
step: 360 @ episode report: {'average_total_reward': np.float32(0.644), 'reward_variance': np.float32(0.077104), 'max_total_reward': np.float32(0.91), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 13568} @ step loss: {'critic_loss': np.float64(20.72092971801758), 'actor_loss': np.float64(-10.400725173950196), 'alpha_loss': np.float64(-0.002397420711349696), 'alpha': np.float64(0.887447839975357)}
step: 370 @ episode report: {'average_total_reward': np.float32(0.62200004), 'reward_variance': np.float32(0.05523601), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 13888} @ step loss: {'critic_loss': np.float64(20.810418701171876), 'actor_loss': np.float64(-10.489140796661378), 'alpha_loss': np.float64(-0.0023482234217226507), 'alpha': np.float64(0.8861013412475586)}
step: 380 @ episode report: {'average_total_reward': np.float32(0.821), 'reward_variance': np.float32(0.27304903), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 14208} @ step loss: {'critic_loss': np.float64(21.05438690185547), 'actor_loss': np.float64(-10.58446445465088), 'alpha_loss': np.float64(-0.0018416221369989215), 'alpha': np.float64(0.8849260210990906)}
step: 390 @ episode report: {'average_total_reward': np.float32(0.56700003), 'reward_variance': np.float32(0.06794101), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 14528} @ step loss: {'critic_loss': np.float64(20.533844566345216), 'actor_loss': np.float64(-10.68055763244629), 'alpha_loss': np.float64(-0.0011967781407292931), 'alpha': np.float64(0.8839986681938171)}
step: 400 @ episode report: {'average_total_reward': np.float32(0.7670001), 'reward_variance': np.float32(0.04126101), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 14848} @ step loss: {'critic_loss': np.float64(20.87357234954834), 'actor_loss': np.float64(-10.782567977905273), 'alpha_loss': np.float64(-0.000509965807577828), 'alpha': np.float64(0.8833442807197571)}
step: 410 @ episode report: {'average_total_reward': np.float32(0.59900004), 'reward_variance': np.float32(0.127709), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 15168} @ step loss: {'critic_loss': np.float64(21.006565856933594), 'actor_loss': np.float64(-10.887401676177978), 'alpha_loss': np.float64(7.154409540817141e-05), 'alpha': np.float64(0.8829879641532898)}
step: 420 @ episode report: {'average_total_reward': np.float32(0.62200004), 'reward_variance': np.float32(0.08471601), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.019999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 15488} @ step loss: {'critic_loss': np.float64(21.662050247192383), 'actor_loss': np.float64(-11.000633049011231), 'alpha_loss': np.float64(0.0008361109881661833), 'alpha': np.float64(0.8829262971878051)}
step: 430 @ episode report: {'average_total_reward': np.float32(0.699), 'reward_variance': np.float32(0.08276902), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 15808} @ step loss: {'critic_loss': np.float64(21.121402931213378), 'actor_loss': np.float64(-11.085961627960206), 'alpha_loss': np.float64(0.0014091870689298958), 'alpha': np.float64(0.8831991672515869)}
step: 440 @ episode report: {'average_total_reward': np.float32(0.76500005), 'reward_variance': np.float32(0.13090502), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 16128} @ step loss: {'critic_loss': np.float64(21.84333610534668), 'actor_loss': np.float64(-11.17658290863037), 'alpha_loss': np.float64(0.0017177586618345232), 'alpha': np.float64(0.8837780654430389)}
step: 450 @ episode report: {'average_total_reward': np.float32(0.765), 'reward_variance': np.float32(0.10626501), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 16448} @ step loss: {'critic_loss': np.float64(22.688652992248535), 'actor_loss': np.float64(-11.30374116897583), 'alpha_loss': np.float64(0.0026863942854106425), 'alpha': np.float64(0.8846477687358856)}
step: 460 @ episode report: {'average_total_reward': np.float32(0.656), 'reward_variance': np.float32(0.042084), 'max_total_reward': np.float32(0.90999997), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 16768} @ step loss: {'critic_loss': np.float64(22.401507949829103), 'actor_loss': np.float64(-11.405140495300293), 'alpha_loss': np.float64(0.0034912846982479095), 'alpha': np.float64(0.8859005630016327)}
step: 470 @ episode report: {'average_total_reward': np.float32(0.54199994), 'reward_variance': np.float32(0.119276024), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 17088} @ step loss: {'critic_loss': np.float64(22.901936721801757), 'actor_loss': np.float64(-11.531398582458497), 'alpha_loss': np.float64(0.00404673139564693), 'alpha': np.float64(0.8875767469406128)}
step: 480 @ episode report: {'average_total_reward': np.float32(0.64299995), 'reward_variance': np.float32(0.104521), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 17408} @ step loss: {'critic_loss': np.float64(23.070237350463866), 'actor_loss': np.float64(-11.667325401306153), 'alpha_loss': np.float64(0.004007747769355774), 'alpha': np.float64(0.889560604095459)}
step: 490 @ episode report: {'average_total_reward': np.float32(0.501), 'reward_variance': np.float32(0.040089004), 'max_total_reward': np.float32(0.8), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 17728} @ step loss: {'critic_loss': np.float64(23.57978210449219), 'actor_loss': np.float64(-11.790161991119385), 'alpha_loss': np.float64(0.004736988712102175), 'alpha': np.float64(0.8918000102043152)}
step: 500 @ episode report: {'average_total_reward': np.float32(0.7440001), 'reward_variance': np.float32(0.110723995), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 18048} @ step loss: {'critic_loss': np.float64(23.824792289733885), 'actor_loss': np.float64(-11.928301239013672), 'alpha_loss': np.float64(0.005188203975558281), 'alpha': np.float64(0.8943861246109008)}
step: 510 @ episode report: {'average_total_reward': np.float32(0.688), 'reward_variance': np.float32(0.218056), 'max_total_reward': np.float32(1.58), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 18368} @ step loss: {'critic_loss': np.float64(24.390473937988283), 'actor_loss': np.float64(-12.051586151123047), 'alpha_loss': np.float64(0.0060522896237671375), 'alpha': np.float64(0.8973243415355683)}
step: 520 @ episode report: {'average_total_reward': np.float32(0.57699996), 'reward_variance': np.float32(0.13818103), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 18688} @ step loss: {'critic_loss': np.float64(24.70386199951172), 'actor_loss': np.float64(-12.171372222900391), 'alpha_loss': np.float64(0.0064217793755233284), 'alpha': np.float64(0.9007367849349975)}
step: 530 @ episode report: {'average_total_reward': np.float32(0.578), 'reward_variance': np.float32(0.11067603), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 19008} @ step loss: {'critic_loss': np.float64(25.1653995513916), 'actor_loss': np.float64(-12.315526962280273), 'alpha_loss': np.float64(0.006841669417917728), 'alpha': np.float64(0.9045348107814789)}
step: 540 @ episode report: {'average_total_reward': np.float32(0.68700004), 'reward_variance': np.float32(0.12146102), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 19328} @ step loss: {'critic_loss': np.float64(25.99437084197998), 'actor_loss': np.float64(-12.436061191558839), 'alpha_loss': np.float64(0.007233809540048241), 'alpha': np.float64(0.9087042868137359)}
step: 550 @ episode report: {'average_total_reward': np.float32(0.665), 'reward_variance': np.float32(0.10610501), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 19648} @ step loss: {'critic_loss': np.float64(26.3609317779541), 'actor_loss': np.float64(-12.59153184890747), 'alpha_loss': np.float64(0.007324653537943959), 'alpha': np.float64(0.9131776809692382)}
step: 560 @ episode report: {'average_total_reward': np.float32(0.63400006), 'reward_variance': np.float32(0.037684), 'max_total_reward': np.float32(0.91), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 19968} @ step loss: {'critic_loss': np.float64(26.747631454467772), 'actor_loss': np.float64(-12.726412868499756), 'alpha_loss': np.float64(0.007452124776318669), 'alpha': np.float64(0.9178992807865143)}
step: 570 @ episode report: {'average_total_reward': np.float32(0.54399997), 'reward_variance': np.float32(0.08178401), 'max_total_reward': np.float32(0.91), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 20288} @ step loss: {'critic_loss': np.float64(27.49706916809082), 'actor_loss': np.float64(-12.88666648864746), 'alpha_loss': np.float64(0.007727731857448817), 'alpha': np.float64(0.9229257643222809)}
step: 580 @ episode report: {'average_total_reward': np.float32(0.49799997), 'reward_variance': np.float32(0.163496), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 20608} @ step loss: {'critic_loss': np.float64(28.02700271606445), 'actor_loss': np.float64(-13.03346815109253), 'alpha_loss': np.float64(0.007505387859418988), 'alpha': np.float64(0.9282319128513337)}
step: 590 @ episode report: {'average_total_reward': np.float32(0.622), 'reward_variance': np.float32(0.06513601), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 20928} @ step loss: {'critic_loss': np.float64(28.39108238220215), 'actor_loss': np.float64(-13.1958984375), 'alpha_loss': np.float64(0.007433460559695959), 'alpha': np.float64(0.9336904287338257)}
step: 600 @ episode report: {'average_total_reward': np.float32(0.53199995), 'reward_variance': np.float32(0.134136), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 21248} @ step loss: {'critic_loss': np.float64(29.388660621643066), 'actor_loss': np.float64(-13.35357208251953), 'alpha_loss': np.float64(0.007261347863823176), 'alpha': np.float64(0.9393229305744171)}
step: 610 @ episode report: {'average_total_reward': np.float32(0.7), 'reward_variance': np.float32(0.082080014), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 21568} @ step loss: {'critic_loss': np.float64(30.301977348327636), 'actor_loss': np.float64(-13.531201076507568), 'alpha_loss': np.float64(0.006937220599502325), 'alpha': np.float64(0.9451593875885009)}
step: 620 @ episode report: {'average_total_reward': np.float32(0.54499996), 'reward_variance': np.float32(0.049945004), 'max_total_reward': np.float32(0.8000001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 21888} @ step loss: {'critic_loss': np.float64(30.898920440673827), 'actor_loss': np.float64(-13.652221775054931), 'alpha_loss': np.float64(0.006598596042022109), 'alpha': np.float64(0.9511645257472991)}
step: 630 @ episode report: {'average_total_reward': np.float32(0.64399993), 'reward_variance': np.float32(0.08216402), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 22208} @ step loss: {'critic_loss': np.float64(30.91586799621582), 'actor_loss': np.float64(-13.785242748260497), 'alpha_loss': np.float64(0.006056872196495533), 'alpha': np.float64(0.9572968006134033)}
step: 640 @ episode report: {'average_total_reward': np.float32(0.73300004), 'reward_variance': np.float32(0.07670102), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 22528} @ step loss: {'critic_loss': np.float64(31.850740814208983), 'actor_loss': np.float64(-13.925900173187255), 'alpha_loss': np.float64(0.005420634103938937), 'alpha': np.float64(0.9635237634181977)}
step: 650 @ episode report: {'average_total_reward': np.float32(0.478), 'reward_variance': np.float32(0.10281601), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(-0.09000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 22848} @ step loss: {'critic_loss': np.float64(32.8355634689331), 'actor_loss': np.float64(-14.059155654907226), 'alpha_loss': np.float64(0.004704183945432305), 'alpha': np.float64(0.9698314249515534)}
step: 660 @ episode report: {'average_total_reward': np.float32(0.599), 'reward_variance': np.float32(0.12044899), 'max_total_reward': np.float32(1.1299999), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 23168} @ step loss: {'critic_loss': np.float64(34.12086181640625), 'actor_loss': np.float64(-14.211338996887207), 'alpha_loss': np.float64(0.0038580475375056267), 'alpha': np.float64(0.9761986315250397)}
step: 670 @ episode report: {'average_total_reward': np.float32(0.521), 'reward_variance': np.float32(0.15132903), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 23488} @ step loss: {'critic_loss': np.float64(35.016570281982425), 'actor_loss': np.float64(-14.339703369140626), 'alpha_loss': np.float64(0.0029621202731505035), 'alpha': np.float64(0.9826045751571655)}
step: 680 @ episode report: {'average_total_reward': np.float32(0.555), 'reward_variance': np.float32(0.103465006), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 23808} @ step loss: {'critic_loss': np.float64(34.81134605407715), 'actor_loss': np.float64(-14.501864337921143), 'alpha_loss': np.float64(0.0019303417182527482), 'alpha': np.float64(0.9890050232410431)}
step: 690 @ episode report: {'average_total_reward': np.float32(0.43199998), 'reward_variance': np.float32(0.10475601), 'max_total_reward': np.float32(0.91), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 24128} @ step loss: {'critic_loss': np.float64(35.669621276855466), 'actor_loss': np.float64(-14.629931831359864), 'alpha_loss': np.float64(0.0008947014139266685), 'alpha': np.float64(0.9953903138637543)}
step: 700 @ episode report: {'average_total_reward': np.float32(0.61), 'reward_variance': np.float32(0.08482001), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 24448} @ step loss: {'critic_loss': np.float64(37.196598815917966), 'actor_loss': np.float64(-14.782296085357666), 'alpha_loss': np.float64(-0.0002082810657157097), 'alpha': np.float64(1.0017703115940093)}
step: 710 @ episode report: {'average_total_reward': np.float32(0.44300002), 'reward_variance': np.float32(0.113060996), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 24768} @ step loss: {'critic_loss': np.float64(36.49097023010254), 'actor_loss': np.float64(-14.89305763244629), 'alpha_loss': np.float64(-0.0014169782400131226), 'alpha': np.float64(1.0082606196403503)}
step: 720 @ episode report: {'average_total_reward': np.float32(0.476), 'reward_variance': np.float32(0.10286403), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 25088} @ step loss: {'critic_loss': np.float64(38.59774742126465), 'actor_loss': np.float64(-15.047439861297608), 'alpha_loss': np.float64(-0.002737843059003353), 'alpha': np.float64(1.0147785425186158)}
step: 730 @ episode report: {'average_total_reward': np.float32(0.698), 'reward_variance': np.float32(0.19081603), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.019999992), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 25408} @ step loss: {'critic_loss': np.float64(39.27756118774414), 'actor_loss': np.float64(-15.215158271789551), 'alpha_loss': np.float64(-0.004164533200673759), 'alpha': np.float64(1.0213266491889954)}
step: 740 @ episode report: {'average_total_reward': np.float32(0.40000004), 'reward_variance': np.float32(0.07785999), 'max_total_reward': np.float32(0.90999997), 'min_total_reward': np.float32(-0.09), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 25728} @ step loss: {'critic_loss': np.float64(39.48433418273926), 'actor_loss': np.float64(-15.35998067855835), 'alpha_loss': np.float64(-0.005495481844991446), 'alpha': np.float64(1.0278952836990356)}
step: 750 @ episode report: {'average_total_reward': np.float32(0.46600008), 'reward_variance': np.float32(0.12322404), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.12999997), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 26048} @ step loss: {'critic_loss': np.float64(40.91799697875977), 'actor_loss': np.float64(-15.482958984375), 'alpha_loss': np.float64(-0.007020786125212908), 'alpha': np.float64(1.0344351291656495)}
step: 760 @ episode report: {'average_total_reward': np.float32(0.455), 'reward_variance': np.float32(0.051405005), 'max_total_reward': np.float32(0.8000001), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 26368} @ step loss: {'critic_loss': np.float64(41.23905563354492), 'actor_loss': np.float64(-15.652722263336182), 'alpha_loss': np.float64(-0.008626484405249357), 'alpha': np.float64(1.0409423232078552)}
step: 770 @ episode report: {'average_total_reward': np.float32(0.509), 'reward_variance': np.float32(0.15120903), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.12999997), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 26688} @ step loss: {'critic_loss': np.float64(42.342293167114256), 'actor_loss': np.float64(-15.801170539855956), 'alpha_loss': np.float64(-0.010498694144189358), 'alpha': np.float64(1.0474987149238586)}
step: 780 @ episode report: {'average_total_reward': np.float32(0.722), 'reward_variance': np.float32(0.095676005), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 27008} @ step loss: {'critic_loss': np.float64(43.1345630645752), 'actor_loss': np.float64(-15.922030353546143), 'alpha_loss': np.float64(-0.012140415515750647), 'alpha': np.float64(1.054126262664795)}
step: 790 @ episode report: {'average_total_reward': np.float32(0.656), 'reward_variance': np.float32(0.06386401), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 27328} @ step loss: {'critic_loss': np.float64(42.454576110839845), 'actor_loss': np.float64(-16.09694347381592), 'alpha_loss': np.float64(-0.01384072406217456), 'alpha': np.float64(1.0607253551483153)}
step: 800 @ episode report: {'average_total_reward': np.float32(0.421), 'reward_variance': np.float32(0.07310899), 'max_total_reward': np.float32(0.8000001), 'min_total_reward': np.float32(0.019999998), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 27648} @ step loss: {'critic_loss': np.float64(44.75728645324707), 'actor_loss': np.float64(-16.258895111083984), 'alpha_loss': np.float64(-0.01586180180311203), 'alpha': np.float64(1.0673218727111817)}
step: 810 @ episode report: {'average_total_reward': np.float32(0.5), 'reward_variance': np.float32(0.089660004), 'max_total_reward': np.float32(0.91), 'min_total_reward': np.float32(-0.09000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 27968} @ step loss: {'critic_loss': np.float64(45.122735595703126), 'actor_loss': np.float64(-16.420879554748534), 'alpha_loss': np.float64(-0.017651987448334693), 'alpha': np.float64(1.0739230632781982)}
step: 820 @ episode report: {'average_total_reward': np.float32(0.656), 'reward_variance': np.float32(0.029984003), 'max_total_reward': np.float32(0.8000001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 28288} @ step loss: {'critic_loss': np.float64(45.49474334716797), 'actor_loss': np.float64(-16.564694786071776), 'alpha_loss': np.float64(-0.019524095207452775), 'alpha': np.float64(1.0804986596107482)}
step: 830 @ episode report: {'average_total_reward': np.float32(0.522), 'reward_variance': np.float32(0.09247601), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.019999992), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 28608} @ step loss: {'critic_loss': np.float64(47.390505981445315), 'actor_loss': np.float64(-16.753952026367188), 'alpha_loss': np.float64(-0.021655062027275563), 'alpha': np.float64(1.0870596408843993)}
step: 840 @ episode report: {'average_total_reward': np.float32(0.67700005), 'reward_variance': np.float32(0.104901016), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 28928} @ step loss: {'critic_loss': np.float64(47.8149772644043), 'actor_loss': np.float64(-16.910485076904298), 'alpha_loss': np.float64(-0.024191484600305558), 'alpha': np.float64(1.0936476230621337)}
step: 850 @ episode report: {'average_total_reward': np.float32(0.599), 'reward_variance': np.float32(0.15256901), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 29248} @ step loss: {'critic_loss': np.float64(48.693219375610354), 'actor_loss': np.float64(-17.04520435333252), 'alpha_loss': np.float64(-0.02634002212435007), 'alpha': np.float64(1.100290870666504)}
step: 860 @ episode report: {'average_total_reward': np.float32(0.61099994), 'reward_variance': np.float32(0.067149006), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 29568} @ step loss: {'critic_loss': np.float64(50.66529731750488), 'actor_loss': np.float64(-17.181832695007323), 'alpha_loss': np.float64(-0.028700112365186214), 'alpha': np.float64(1.1069453477859497)}
step: 870 @ episode report: {'average_total_reward': np.float32(0.654), 'reward_variance': np.float32(0.11170403), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 29888} @ step loss: {'critic_loss': np.float64(51.26943473815918), 'actor_loss': np.float64(-17.33410701751709), 'alpha_loss': np.float64(-0.030635539069771768), 'alpha': np.float64(1.1135969042778016)}
step: 880 @ episode report: {'average_total_reward': np.float32(0.66700006), 'reward_variance': np.float32(0.06086101), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.24000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 30208} @ step loss: {'critic_loss': np.float64(51.80092430114746), 'actor_loss': np.float64(-17.498202896118165), 'alpha_loss': np.float64(-0.03291406407952309), 'alpha': np.float64(1.1202220559120177)}
step: 890 @ episode report: {'average_total_reward': np.float32(0.7110001), 'reward_variance': np.float32(0.049069006), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 30528} @ step loss: {'critic_loss': np.float64(52.714493942260745), 'actor_loss': np.float64(-17.61737403869629), 'alpha_loss': np.float64(-0.03517237678170204), 'alpha': np.float64(1.1268110990524292)}
step: 900 @ episode report: {'average_total_reward': np.float32(0.44399995), 'reward_variance': np.float32(0.091544), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.019999998), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 30848} @ step loss: {'critic_loss': np.float64(52.87374038696289), 'actor_loss': np.float64(-17.75062255859375), 'alpha_loss': np.float64(-0.038515737280249596), 'alpha': np.float64(1.133420968055725)}
step: 910 @ episode report: {'average_total_reward': np.float32(0.27600002), 'reward_variance': np.float32(0.079364024), 'max_total_reward': np.float32(1.0200002), 'min_total_reward': np.float32(-0.09000001), 'average_n_step': np.float32(2.3), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 31168} @ step loss: {'critic_loss': np.float64(54.75905799865723), 'actor_loss': np.float64(-17.87610607147217), 'alpha_loss': np.float64(-0.040359460189938544), 'alpha': np.float64(1.1400739669799804)}
step: 920 @ episode report: {'average_total_reward': np.float32(0.77700007), 'reward_variance': np.float32(0.09518102), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 31488} @ step loss: {'critic_loss': np.float64(54.423932266235354), 'actor_loss': np.float64(-17.978853607177733), 'alpha_loss': np.float64(-0.04312657043337822), 'alpha': np.float64(1.1467056751251221)}
step: 930 @ episode report: {'average_total_reward': np.float32(0.477), 'reward_variance': np.float32(0.142441), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(-0.09), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 31808} @ step loss: {'critic_loss': np.float64(55.18391876220703), 'actor_loss': np.float64(-18.12766876220703), 'alpha_loss': np.float64(-0.045230991765856744), 'alpha': np.float64(1.1533355951309203)}
step: 940 @ episode report: {'average_total_reward': np.float32(0.71), 'reward_variance': np.float32(0.11534001), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 32128} @ step loss: {'critic_loss': np.float64(57.164411544799805), 'actor_loss': np.float64(-18.237947273254395), 'alpha_loss': np.float64(-0.047180712968111035), 'alpha': np.float64(1.1599088072776795)}
step: 950 @ episode report: {'average_total_reward': np.float32(0.45600003), 'reward_variance': np.float32(0.07320402), 'max_total_reward': np.float32(0.91000015), 'min_total_reward': np.float32(0.02), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 32448} @ step loss: {'critic_loss': np.float64(57.393472290039064), 'actor_loss': np.float64(-18.359245109558106), 'alpha_loss': np.float64(-0.04954104572534561), 'alpha': np.float64(1.1664295673370362)}
step: 960 @ episode report: {'average_total_reward': np.float32(0.499), 'reward_variance': np.float32(0.10710901), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.019999983), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 32768} @ step loss: {'critic_loss': np.float64(59.25504417419434), 'actor_loss': np.float64(-18.5118616104126), 'alpha_loss': np.float64(-0.05224725566804409), 'alpha': np.float64(1.1729267239570618)}
step: 970 @ episode report: {'average_total_reward': np.float32(0.41), 'reward_variance': np.float32(0.13186002), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 33088} @ step loss: {'critic_loss': np.float64(60.37537117004395), 'actor_loss': np.float64(-18.6841157913208), 'alpha_loss': np.float64(-0.054655400663614274), 'alpha': np.float64(1.1794074654579163)}
step: 980 @ episode report: {'average_total_reward': np.float32(0.72200006), 'reward_variance': np.float32(0.06179601), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 33408} @ step loss: {'critic_loss': np.float64(59.5430721282959), 'actor_loss': np.float64(-18.778296852111815), 'alpha_loss': np.float64(-0.056384723633527756), 'alpha': np.float64(1.1858754992485045)}
step: 990 @ episode report: {'average_total_reward': np.float32(0.721), 'reward_variance': np.float32(0.091569014), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 33728} @ step loss: {'critic_loss': np.float64(61.911163330078125), 'actor_loss': np.float64(-18.946281814575194), 'alpha_loss': np.float64(-0.05815219134092331), 'alpha': np.float64(1.1922738075256347)}
step: 1000 @ episode report: {'average_total_reward': np.float32(0.721), 'reward_variance': np.float32(0.09178902), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 34048} @ step loss: {'critic_loss': np.float64(63.714793014526364), 'actor_loss': np.float64(-19.067508888244628), 'alpha_loss': np.float64(-0.06122167371213436), 'alpha': np.float64(1.198626697063446)}
step: 1010 @ episode report: {'average_total_reward': np.float32(0.45700002), 'reward_variance': np.float32(0.077181), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.13000004), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 34368} @ step loss: {'critic_loss': np.float64(62.95284309387207), 'actor_loss': np.float64(-19.189474296569824), 'alpha_loss': np.float64(-0.06336887292563916), 'alpha': np.float64(1.2049744725227356)}
step: 1020 @ episode report: {'average_total_reward': np.float32(0.599), 'reward_variance': np.float32(0.23288901), 'max_total_reward': np.float32(1.69), 'min_total_reward': np.float32(0.019999983), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 34688} @ step loss: {'critic_loss': np.float64(64.40371208190918), 'actor_loss': np.float64(-19.342889022827148), 'alpha_loss': np.float64(-0.06583285927772523), 'alpha': np.float64(1.211318552494049)}
step: 1030 @ episode report: {'average_total_reward': np.float32(0.61100006), 'reward_variance': np.float32(0.11356902), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.019999988), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 35008} @ step loss: {'critic_loss': np.float64(66.66904220581054), 'actor_loss': np.float64(-19.46711654663086), 'alpha_loss': np.float64(-0.06799162328243255), 'alpha': np.float64(1.2176393747329712)}
step: 1040 @ episode report: {'average_total_reward': np.float32(0.60999995), 'reward_variance': np.float32(0.11914001), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 35328} @ step loss: {'critic_loss': np.float64(66.19380912780761), 'actor_loss': np.float64(-19.508611488342286), 'alpha_loss': np.float64(-0.07075037136673927), 'alpha': np.float64(1.2239453792572021)}
step: 1050 @ episode report: {'average_total_reward': np.float32(0.525), 'reward_variance': np.float32(0.034485012), 'max_total_reward': np.float32(0.8000001), 'min_total_reward': np.float32(0.24999996), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 35648} @ step loss: {'critic_loss': np.float64(68.32233657836915), 'actor_loss': np.float64(-19.667257881164552), 'alpha_loss': np.float64(-0.07228016704320908), 'alpha': np.float64(1.2302369832992555)}
step: 1060 @ episode report: {'average_total_reward': np.float32(0.533), 'reward_variance': np.float32(0.05810101), 'max_total_reward': np.float32(0.91), 'min_total_reward': np.float32(0.12999997), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 35968} @ step loss: {'critic_loss': np.float64(67.82538223266602), 'actor_loss': np.float64(-19.712062072753906), 'alpha_loss': np.float64(-0.0742842748761177), 'alpha': np.float64(1.2364930272102357)}
step: 1070 @ episode report: {'average_total_reward': np.float32(0.487), 'reward_variance': np.float32(0.123621024), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.12999997), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 36288} @ step loss: {'critic_loss': np.float64(68.96289405822753), 'actor_loss': np.float64(-19.83661632537842), 'alpha_loss': np.float64(-0.07553473636507987), 'alpha': np.float64(1.2426870822906495)}
step: 1080 @ episode report: {'average_total_reward': np.float32(0.277), 'reward_variance': np.float32(0.040581), 'max_total_reward': np.float32(0.58), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.4), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 36608} @ step loss: {'critic_loss': np.float64(69.4615966796875), 'actor_loss': np.float64(-19.9978458404541), 'alpha_loss': np.float64(-0.0774971179664135), 'alpha': np.float64(1.2488227844238282)}
step: 1090 @ episode report: {'average_total_reward': np.float32(0.65599996), 'reward_variance': np.float32(0.15386403), 'max_total_reward': np.float32(1.6900002), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 36928} @ step loss: {'critic_loss': np.float64(69.06811065673828), 'actor_loss': np.float64(-20.103611373901366), 'alpha_loss': np.float64(-0.07946384847164153), 'alpha': np.float64(1.254918384552002)}
step: 1100 @ episode report: {'average_total_reward': np.float32(0.62200004), 'reward_variance': np.float32(0.123436), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 37248} @ step loss: {'critic_loss': np.float64(72.55996017456054), 'actor_loss': np.float64(-20.25888843536377), 'alpha_loss': np.float64(-0.0814977802336216), 'alpha': np.float64(1.2609857439994812)}
step: 1110 @ episode report: {'average_total_reward': np.float32(0.653), 'reward_variance': np.float32(0.16092102), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 37568} @ step loss: {'critic_loss': np.float64(71.57161026000976), 'actor_loss': np.float64(-20.412324714660645), 'alpha_loss': np.float64(-0.08441145718097687), 'alpha': np.float64(1.267042863368988)}
step: 1120 @ episode report: {'average_total_reward': np.float32(0.51), 'reward_variance': np.float32(0.10734), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.019999992), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 37888} @ step loss: {'critic_loss': np.float64(74.6849136352539), 'actor_loss': np.float64(-20.512192153930663), 'alpha_loss': np.float64(-0.08444088026881218), 'alpha': np.float64(1.273090696334839)}
step: 1130 @ episode report: {'average_total_reward': np.float32(0.589), 'reward_variance': np.float32(0.121709004), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.019999994), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 38208} @ step loss: {'critic_loss': np.float64(75.41461334228515), 'actor_loss': np.float64(-20.64372272491455), 'alpha_loss': np.float64(-0.0870519034564495), 'alpha': np.float64(1.2790726661682128)}
step: 1140 @ episode report: {'average_total_reward': np.float32(0.476), 'reward_variance': np.float32(0.14730403), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.019999992), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 38528} @ step loss: {'critic_loss': np.float64(72.97638473510742), 'actor_loss': np.float64(-20.729729080200194), 'alpha_loss': np.float64(-0.08876671269536018), 'alpha': np.float64(1.2850396990776063)}
step: 1150 @ episode report: {'average_total_reward': np.float32(0.588), 'reward_variance': np.float32(0.080596015), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 38848} @ step loss: {'critic_loss': np.float64(75.79215850830079), 'actor_loss': np.float64(-20.885431480407714), 'alpha_loss': np.float64(-0.09014668539166451), 'alpha': np.float64(1.2909791946411133)}
step: 1160 @ episode report: {'average_total_reward': np.float32(0.532), 'reward_variance': np.float32(0.10729601), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 39168} @ step loss: {'critic_loss': np.float64(74.81070175170899), 'actor_loss': np.float64(-21.00004348754883), 'alpha_loss': np.float64(-0.0931148312985897), 'alpha': np.float64(1.296889078617096)}
step: 1170 @ episode report: {'average_total_reward': np.float32(0.656), 'reward_variance': np.float32(0.078384005), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.24000004), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 39488} @ step loss: {'critic_loss': np.float64(75.56845550537109), 'actor_loss': np.float64(-21.13627986907959), 'alpha_loss': np.float64(-0.09466697946190834), 'alpha': np.float64(1.302817463874817)}
step: 1180 @ episode report: {'average_total_reward': np.float32(0.5990001), 'reward_variance': np.float32(0.12792902), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 39808} @ step loss: {'critic_loss': np.float64(78.99594421386719), 'actor_loss': np.float64(-21.288709449768067), 'alpha_loss': np.float64(-0.09661030396819115), 'alpha': np.float64(1.3087302088737487)}
step: 1190 @ episode report: {'average_total_reward': np.float32(0.588), 'reward_variance': np.float32(0.149016), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 40128} @ step loss: {'critic_loss': np.float64(77.7552719116211), 'actor_loss': np.float64(-21.40144214630127), 'alpha_loss': np.float64(-0.09837015494704246), 'alpha': np.float64(1.3146387338638306)}
step: 1200 @ episode report: {'average_total_reward': np.float32(0.7110001), 'reward_variance': np.float32(0.061169), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 40448} @ step loss: {'critic_loss': np.float64(78.86439971923828), 'actor_loss': np.float64(-21.588306045532228), 'alpha_loss': np.float64(-0.09993587955832481), 'alpha': np.float64(1.3205224394798278)}
step: 1210 @ episode report: {'average_total_reward': np.float32(0.64500004), 'reward_variance': np.float32(0.06926502), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 40768} @ step loss: {'critic_loss': np.float64(80.32105407714843), 'actor_loss': np.float64(-21.693850708007812), 'alpha_loss': np.float64(-0.10143068507313728), 'alpha': np.float64(1.32638019323349)}
step: 1220 @ episode report: {'average_total_reward': np.float32(0.598), 'reward_variance': np.float32(0.16999604), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 41088} @ step loss: {'critic_loss': np.float64(82.13926162719727), 'actor_loss': np.float64(-21.797154808044432), 'alpha_loss': np.float64(-0.10307546705007553), 'alpha': np.float64(1.3322274446487428)}
step: 1230 @ episode report: {'average_total_reward': np.float32(0.59900004), 'reward_variance': np.float32(0.101309), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.019999988), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 41408} @ step loss: {'critic_loss': np.float64(84.30348434448243), 'actor_loss': np.float64(-21.9649808883667), 'alpha_loss': np.float64(-0.10562989786267281), 'alpha': np.float64(1.338054120540619)}
step: 1240 @ episode report: {'average_total_reward': np.float32(0.778), 'reward_variance': np.float32(0.035815995), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 41728} @ step loss: {'critic_loss': np.float64(85.30345764160157), 'actor_loss': np.float64(-22.02308120727539), 'alpha_loss': np.float64(-0.10701060518622399), 'alpha': np.float64(1.3438851714134217)}
step: 1250 @ episode report: {'average_total_reward': np.float32(0.588), 'reward_variance': np.float32(0.09533601), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 42048} @ step loss: {'critic_loss': np.float64(86.09463882446289), 'actor_loss': np.float64(-22.140389823913573), 'alpha_loss': np.float64(-0.10773840472102165), 'alpha': np.float64(1.3496957302093506)}
step: 1260 @ episode report: {'average_total_reward': np.float32(0.7440001), 'reward_variance': np.float32(0.123044014), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.019999994), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 42368} @ step loss: {'critic_loss': np.float64(85.9289306640625), 'actor_loss': np.float64(-22.23739585876465), 'alpha_loss': np.float64(-0.10889599248766899), 'alpha': np.float64(1.3554693341255188)}
step: 1270 @ episode report: {'average_total_reward': np.float32(0.679), 'reward_variance': np.float32(0.027709002), 'max_total_reward': np.float32(0.91), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 42688} @ step loss: {'critic_loss': np.float64(86.65532913208008), 'actor_loss': np.float64(-22.372591018676758), 'alpha_loss': np.float64(-0.109564658254385), 'alpha': np.float64(1.361192488670349)}
step: 1280 @ episode report: {'average_total_reward': np.float32(0.6090001), 'reward_variance': np.float32(0.095009014), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 43008} @ step loss: {'critic_loss': np.float64(87.32835235595704), 'actor_loss': np.float64(-22.465623092651366), 'alpha_loss': np.float64(-0.11033153533935547), 'alpha': np.float64(1.3668739914894104)}
step: 1290 @ episode report: {'average_total_reward': np.float32(0.565), 'reward_variance': np.float32(0.122465014), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 43328} @ step loss: {'critic_loss': np.float64(90.37289352416992), 'actor_loss': np.float64(-22.593429183959962), 'alpha_loss': np.float64(-0.11279615461826324), 'alpha': np.float64(1.372527050971985)}
step: 1300 @ episode report: {'average_total_reward': np.float32(0.444), 'reward_variance': np.float32(0.07922401), 'max_total_reward': np.float32(0.90999997), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 43648} @ step loss: {'critic_loss': np.float64(91.16120758056641), 'actor_loss': np.float64(-22.668182945251466), 'alpha_loss': np.float64(-0.11404763460159302), 'alpha': np.float64(1.378173053264618)}
step: 1310 @ episode report: {'average_total_reward': np.float32(0.78700006), 'reward_variance': np.float32(0.11964103), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 43968} @ step loss: {'critic_loss': np.float64(93.17375564575195), 'actor_loss': np.float64(-22.743131637573242), 'alpha_loss': np.float64(-0.11528190374374389), 'alpha': np.float64(1.3838102102279664)}
step: 1320 @ episode report: {'average_total_reward': np.float32(0.644), 'reward_variance': np.float32(0.17194399), 'max_total_reward': np.float32(1.58), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 44288} @ step loss: {'critic_loss': np.float64(89.45402526855469), 'actor_loss': np.float64(-22.792585182189942), 'alpha_loss': np.float64(-0.11597420573234558), 'alpha': np.float64(1.3894284963607788)}
step: 1330 @ episode report: {'average_total_reward': np.float32(0.699), 'reward_variance': np.float32(0.12170903), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 44608} @ step loss: {'critic_loss': np.float64(90.38459014892578), 'actor_loss': np.float64(-22.985744094848634), 'alpha_loss': np.float64(-0.11806437894701957), 'alpha': np.float64(1.3950164198875428)}
step: 1340 @ episode report: {'average_total_reward': np.float32(0.65500003), 'reward_variance': np.float32(0.12826502), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(-0.09000001), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 44928} @ step loss: {'critic_loss': np.float64(94.76288375854492), 'actor_loss': np.float64(-23.107505226135252), 'alpha_loss': np.float64(-0.11853714063763618), 'alpha': np.float64(1.400593137741089)}
step: 1350 @ episode report: {'average_total_reward': np.float32(0.56500006), 'reward_variance': np.float32(0.118065014), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 45248} @ step loss: {'critic_loss': np.float64(95.70874862670898), 'actor_loss': np.float64(-23.220773696899414), 'alpha_loss': np.float64(-0.11951332241296768), 'alpha': np.float64(1.406157124042511)}
step: 1360 @ episode report: {'average_total_reward': np.float32(0.711), 'reward_variance': np.float32(0.27304906), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 45568} @ step loss: {'critic_loss': np.float64(98.30435256958008), 'actor_loss': np.float64(-23.344957733154295), 'alpha_loss': np.float64(-0.12068067789077759), 'alpha': np.float64(1.4116990208625793)}
step: 1370 @ episode report: {'average_total_reward': np.float32(0.455), 'reward_variance': np.float32(0.061305005), 'max_total_reward': np.float32(0.90999997), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.6), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 45888} @ step loss: {'critic_loss': np.float64(95.62341995239258), 'actor_loss': np.float64(-23.361488151550294), 'alpha_loss': np.float64(-0.12186131179332733), 'alpha': np.float64(1.417215931415558)}
step: 1380 @ episode report: {'average_total_reward': np.float32(0.689), 'reward_variance': np.float32(0.083609), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 46208} @ step loss: {'critic_loss': np.float64(96.08384780883789), 'actor_loss': np.float64(-23.5409273147583), 'alpha_loss': np.float64(-0.12340834364295006), 'alpha': np.float64(1.42271488904953)}
step: 1390 @ episode report: {'average_total_reward': np.float32(0.588), 'reward_variance': np.float32(0.10985601), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 46528} @ step loss: {'critic_loss': np.float64(103.01565322875976), 'actor_loss': np.float64(-23.628352165222168), 'alpha_loss': np.float64(-0.12402196303009987), 'alpha': np.float64(1.428213858604431)}
step: 1400 @ episode report: {'average_total_reward': np.float32(0.66699994), 'reward_variance': np.float32(0.065701), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 46848} @ step loss: {'critic_loss': np.float64(99.50205841064454), 'actor_loss': np.float64(-23.682330322265624), 'alpha_loss': np.float64(-0.12404182702302932), 'alpha': np.float64(1.4336868405342102)}
step: 1410 @ episode report: {'average_total_reward': np.float32(0.53300005), 'reward_variance': np.float32(0.07768101), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 47168} @ step loss: {'critic_loss': np.float64(97.4844757080078), 'actor_loss': np.float64(-23.778375816345214), 'alpha_loss': np.float64(-0.12569667920470237), 'alpha': np.float64(1.4391218185424806)}
step: 1420 @ episode report: {'average_total_reward': np.float32(0.788), 'reward_variance': np.float32(0.067516), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 47488} @ step loss: {'critic_loss': np.float64(102.23317642211914), 'actor_loss': np.float64(-23.86744785308838), 'alpha_loss': np.float64(-0.1252961851656437), 'alpha': np.float64(1.4445399641990662)}
step: 1430 @ episode report: {'average_total_reward': np.float32(0.8450001), 'reward_variance': np.float32(0.19136503), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 47808} @ step loss: {'critic_loss': np.float64(99.8676742553711), 'actor_loss': np.float64(-24.005804824829102), 'alpha_loss': np.float64(-0.12550057247281074), 'alpha': np.float64(1.4499148607254029)}
step: 1440 @ episode report: {'average_total_reward': np.float32(0.35400003), 'reward_variance': np.float32(0.07504401), 'max_total_reward': np.float32(0.80000013), 'min_total_reward': np.float32(0.02), 'average_n_step': np.float32(2.4), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 48128} @ step loss: {'critic_loss': np.float64(104.75990982055664), 'actor_loss': np.float64(-24.134304237365722), 'alpha_loss': np.float64(-0.12508958503603934), 'alpha': np.float64(1.4552387237548827)}
step: 1450 @ episode report: {'average_total_reward': np.float32(0.8890001), 'reward_variance': np.float32(0.30032903), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(-0.09), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 48448} @ step loss: {'critic_loss': np.float64(102.16735382080078), 'actor_loss': np.float64(-24.241961097717287), 'alpha_loss': np.float64(-0.1259342610836029), 'alpha': np.float64(1.4605116724967957)}
step: 1460 @ episode report: {'average_total_reward': np.float32(0.643), 'reward_variance': np.float32(0.14566101), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 48768} @ step loss: {'critic_loss': np.float64(104.52480621337891), 'actor_loss': np.float64(-24.336049270629882), 'alpha_loss': np.float64(-0.12769097536802293), 'alpha': np.float64(1.4657690882682801)}
step: 1470 @ episode report: {'average_total_reward': np.float32(0.7), 'reward_variance': np.float32(0.077020004), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 49088} @ step loss: {'critic_loss': np.float64(102.74011688232422), 'actor_loss': np.float64(-24.428390502929688), 'alpha_loss': np.float64(-0.1290558844804764), 'alpha': np.float64(1.471032154560089)}
step: 1480 @ episode report: {'average_total_reward': np.float32(0.755), 'reward_variance': np.float32(0.049905006), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.24000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 49408} @ step loss: {'critic_loss': np.float64(108.0153190612793), 'actor_loss': np.float64(-24.590516090393066), 'alpha_loss': np.float64(-0.12774969190359114), 'alpha': np.float64(1.4762804508209229)}
step: 1490 @ episode report: {'average_total_reward': np.float32(0.555), 'reward_variance': np.float32(0.095984995), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 49728} @ step loss: {'critic_loss': np.float64(107.10940704345703), 'actor_loss': np.float64(-24.661018562316894), 'alpha_loss': np.float64(-0.12924171835184098), 'alpha': np.float64(1.4814970374107361)}
step: 1500 @ episode report: {'average_total_reward': np.float32(0.465), 'reward_variance': np.float32(0.11442502), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.5), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 50048} @ step loss: {'critic_loss': np.float64(109.63165512084962), 'actor_loss': np.float64(-24.80567684173584), 'alpha_loss': np.float64(-0.13007362186908722), 'alpha': np.float64(1.4867048263549805)}
step: 1510 @ episode report: {'average_total_reward': np.float32(0.7), 'reward_variance': np.float32(0.08186001), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 50368} @ step loss: {'critic_loss': np.float64(111.61594848632812), 'actor_loss': np.float64(-24.881815910339355), 'alpha_loss': np.float64(-0.1320964053273201), 'alpha': np.float64(1.49190411567688)}
step: 1520 @ episode report: {'average_total_reward': np.float32(0.58800006), 'reward_variance': np.float32(0.13449603), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 50688} @ step loss: {'critic_loss': np.float64(111.24033279418946), 'actor_loss': np.float64(-24.973243713378906), 'alpha_loss': np.float64(-0.1318808004260063), 'alpha': np.float64(1.4971169590950013)}
step: 1530 @ episode report: {'average_total_reward': np.float32(0.721), 'reward_variance': np.float32(0.11334902), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 51008} @ step loss: {'critic_loss': np.float64(107.49782867431641), 'actor_loss': np.float64(-25.057583236694335), 'alpha_loss': np.float64(-0.13373081684112548), 'alpha': np.float64(1.5023296236991883)}
step: 1540 @ episode report: {'average_total_reward': np.float32(0.811), 'reward_variance': np.float32(0.08578901), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.47), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 51328} @ step loss: {'critic_loss': np.float64(116.92314682006835), 'actor_loss': np.float64(-25.238982009887696), 'alpha_loss': np.float64(-0.13536457121372222), 'alpha': np.float64(1.507547175884247)}
step: 1550 @ episode report: {'average_total_reward': np.float32(0.754), 'reward_variance': np.float32(0.13826402), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 51648} @ step loss: {'critic_loss': np.float64(115.64034576416016), 'actor_loss': np.float64(-25.2796875), 'alpha_loss': np.float64(-0.13400407433509826), 'alpha': np.float64(1.5127688288688659)}
step: 1560 @ episode report: {'average_total_reward': np.float32(0.39800003), 'reward_variance': np.float32(0.12709603), 'max_total_reward': np.float32(1.0200001), 'min_total_reward': np.float32(-0.09000002), 'average_n_step': np.float32(2.4), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 51968} @ step loss: {'critic_loss': np.float64(111.21973342895508), 'actor_loss': np.float64(-25.35631275177002), 'alpha_loss': np.float64(-0.13505077362060547), 'alpha': np.float64(1.5179526090621949)}
step: 1570 @ episode report: {'average_total_reward': np.float32(0.83100003), 'reward_variance': np.float32(0.09926902), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 52288} @ step loss: {'critic_loss': np.float64(112.7579849243164), 'actor_loss': np.float64(-25.476108932495116), 'alpha_loss': np.float64(-0.13674910217523575), 'alpha': np.float64(1.5231377124786376)}
step: 1580 @ episode report: {'average_total_reward': np.float32(0.81000006), 'reward_variance': np.float32(0.10628003), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 52608} @ step loss: {'critic_loss': np.float64(117.01120071411133), 'actor_loss': np.float64(-25.6014892578125), 'alpha_loss': np.float64(-0.13720615655183793), 'alpha': np.float64(1.5283296704292297)}
step: 1590 @ episode report: {'average_total_reward': np.float32(0.855), 'reward_variance': np.float32(0.04174501), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 52928} @ step loss: {'critic_loss': np.float64(116.39435958862305), 'actor_loss': np.float64(-25.75707893371582), 'alpha_loss': np.float64(-0.13815573751926422), 'alpha': np.float64(1.5335155487060548)}
step: 1600 @ episode report: {'average_total_reward': np.float32(0.72), 'reward_variance': np.float32(0.15082005), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 53248} @ step loss: {'critic_loss': np.float64(117.57155075073243), 'actor_loss': np.float64(-25.861228942871094), 'alpha_loss': np.float64(-0.13990822285413743), 'alpha': np.float64(1.5387087225914002)}
step: 1610 @ episode report: {'average_total_reward': np.float32(1.031), 'reward_variance': np.float32(0.22000901), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 53568} @ step loss: {'critic_loss': np.float64(120.00230865478515), 'actor_loss': np.float64(-25.948297882080077), 'alpha_loss': np.float64(-0.1403609797358513), 'alpha': np.float64(1.543908131122589)}
step: 1620 @ episode report: {'average_total_reward': np.float32(0.99800014), 'reward_variance': np.float32(0.19643603), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 53888} @ step loss: {'critic_loss': np.float64(116.03795700073242), 'actor_loss': np.float64(-26.055571174621583), 'alpha_loss': np.float64(-0.14176227152347565), 'alpha': np.float64(1.5491175770759582)}
step: 1630 @ episode report: {'average_total_reward': np.float32(0.6880001), 'reward_variance': np.float32(0.07943601), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 54208} @ step loss: {'critic_loss': np.float64(126.61830291748046), 'actor_loss': np.float64(-26.14505615234375), 'alpha_loss': np.float64(-0.1437265858054161), 'alpha': np.float64(1.5543431162834167)}
step: 1640 @ episode report: {'average_total_reward': np.float32(0.722), 'reward_variance': np.float32(0.039796002), 'max_total_reward': np.float32(0.9100001), 'min_total_reward': np.float32(0.24000005), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 54528} @ step loss: {'critic_loss': np.float64(122.82853469848632), 'actor_loss': np.float64(-26.18068199157715), 'alpha_loss': np.float64(-0.14303300082683562), 'alpha': np.float64(1.5595804095268249)}
step: 1650 @ episode report: {'average_total_reward': np.float32(0.73300004), 'reward_variance': np.float32(0.062181007), 'max_total_reward': np.float32(1.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 54848} @ step loss: {'critic_loss': np.float64(117.1895538330078), 'actor_loss': np.float64(-26.2741268157959), 'alpha_loss': np.float64(-0.1443893477320671), 'alpha': np.float64(1.5648089289665221)}
step: 1660 @ episode report: {'average_total_reward': np.float32(0.84300005), 'reward_variance': np.float32(0.11564102), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 55168} @ step loss: {'critic_loss': np.float64(121.17210388183594), 'actor_loss': np.float64(-26.49608745574951), 'alpha_loss': np.float64(-0.14428747296333314), 'alpha': np.float64(1.5700342297554015)}
step: 1670 @ episode report: {'average_total_reward': np.float32(0.888), 'reward_variance': np.float32(0.016456008), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 55488} @ step loss: {'critic_loss': np.float64(121.98563537597656), 'actor_loss': np.float64(-26.62010726928711), 'alpha_loss': np.float64(-0.14684692174196243), 'alpha': np.float64(1.5752583622932435)}
step: 1680 @ episode report: {'average_total_reward': np.float32(0.77800006), 'reward_variance': np.float32(0.06727602), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.36), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 55808} @ step loss: {'critic_loss': np.float64(125.24145126342773), 'actor_loss': np.float64(-26.71658248901367), 'alpha_loss': np.float64(-0.1466234028339386), 'alpha': np.float64(1.5804979801177979)}
step: 1690 @ episode report: {'average_total_reward': np.float32(0.83100003), 'reward_variance': np.float32(0.20378904), 'max_total_reward': np.float32(1.69), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 56128} @ step loss: {'critic_loss': np.float64(132.0631576538086), 'actor_loss': np.float64(-26.84495143890381), 'alpha_loss': np.float64(-0.1478196144104004), 'alpha': np.float64(1.5857322096824646)}
step: 1700 @ episode report: {'average_total_reward': np.float32(1.0320001), 'reward_variance': np.float32(0.07741601), 'max_total_reward': np.float32(1.69), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 56448} @ step loss: {'critic_loss': np.float64(127.06867294311523), 'actor_loss': np.float64(-26.878084182739258), 'alpha_loss': np.float64(-0.14755507111549376), 'alpha': np.float64(1.5909608721733093)}
step: 1710 @ episode report: {'average_total_reward': np.float32(0.82), 'reward_variance': np.float32(0.13250002), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 56768} @ step loss: {'critic_loss': np.float64(128.10791931152343), 'actor_loss': np.float64(-27.01416130065918), 'alpha_loss': np.float64(-0.14870669543743134), 'alpha': np.float64(1.5961756348609923)}
step: 1720 @ episode report: {'average_total_reward': np.float32(0.86500007), 'reward_variance': np.float32(0.06222499), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.24000005), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 57088} @ step loss: {'critic_loss': np.float64(128.85845718383788), 'actor_loss': np.float64(-27.08043975830078), 'alpha_loss': np.float64(-0.14797831624746322), 'alpha': np.float64(1.6013876438140868)}
step: 1730 @ episode report: {'average_total_reward': np.float32(0.87600005), 'reward_variance': np.float32(0.19566402), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 57408} @ step loss: {'critic_loss': np.float64(131.83257980346679), 'actor_loss': np.float64(-27.233212852478026), 'alpha_loss': np.float64(-0.14751970916986465), 'alpha': np.float64(1.606573498249054)}
step: 1740 @ episode report: {'average_total_reward': np.float32(0.94200003), 'reward_variance': np.float32(0.186116), 'max_total_reward': np.float32(1.6899999), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 57728} @ step loss: {'critic_loss': np.float64(133.79864044189452), 'actor_loss': np.float64(-27.350662422180175), 'alpha_loss': np.float64(-0.1485967978835106), 'alpha': np.float64(1.6117291450500488)}
step: 1750 @ episode report: {'average_total_reward': np.float32(0.8320001), 'reward_variance': np.float32(0.10777602), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.24000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 58048} @ step loss: {'critic_loss': np.float64(127.18615646362305), 'actor_loss': np.float64(-27.410014343261718), 'alpha_loss': np.float64(-0.1490547925233841), 'alpha': np.float64(1.6168792724609375)}
step: 1760 @ episode report: {'average_total_reward': np.float32(0.622), 'reward_variance': np.float32(0.11397602), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.019999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 58368} @ step loss: {'critic_loss': np.float64(131.6176773071289), 'actor_loss': np.float64(-27.566161918640137), 'alpha_loss': np.float64(-0.14902788102626802), 'alpha': np.float64(1.6220206022262573)}
step: 1770 @ episode report: {'average_total_reward': np.float32(0.766), 'reward_variance': np.float32(0.11798401), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(-0.09000001), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 58688} @ step loss: {'critic_loss': np.float64(143.8532745361328), 'actor_loss': np.float64(-27.654843139648438), 'alpha_loss': np.float64(-0.14901189953088761), 'alpha': np.float64(1.6271397709846496)}
step: 1780 @ episode report: {'average_total_reward': np.float32(0.76500005), 'reward_variance': np.float32(0.11594503), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 59008} @ step loss: {'critic_loss': np.float64(142.38338165283204), 'actor_loss': np.float64(-27.68735294342041), 'alpha_loss': np.float64(-0.1488366812467575), 'alpha': np.float64(1.6322504162788392)}
step: 1790 @ episode report: {'average_total_reward': np.float32(0.809), 'reward_variance': np.float32(0.24888904), 'max_total_reward': np.float32(1.69), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 59328} @ step loss: {'critic_loss': np.float64(138.41341552734374), 'actor_loss': np.float64(-27.689184761047365), 'alpha_loss': np.float64(-0.14882498234510422), 'alpha': np.float64(1.6373319268226623)}
step: 1800 @ episode report: {'average_total_reward': np.float32(0.687), 'reward_variance': np.float32(0.16502102), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 59648} @ step loss: {'critic_loss': np.float64(138.1215026855469), 'actor_loss': np.float64(-27.748023986816406), 'alpha_loss': np.float64(-0.14814053028821944), 'alpha': np.float64(1.6423951268196106)}
step: 1810 @ episode report: {'average_total_reward': np.float32(0.987), 'reward_variance': np.float32(0.026741004), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 59968} @ step loss: {'critic_loss': np.float64(136.32750549316407), 'actor_loss': np.float64(-27.901751708984374), 'alpha_loss': np.float64(-0.14808248579502106), 'alpha': np.float64(1.647430658340454)}
step: 1820 @ episode report: {'average_total_reward': np.float32(0.70900005), 'reward_variance': np.float32(0.13826902), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 60288} @ step loss: {'critic_loss': np.float64(142.01378326416017), 'actor_loss': np.float64(-28.04578514099121), 'alpha_loss': np.float64(-0.1471441686153412), 'alpha': np.float64(1.652437961101532)}
step: 1830 @ episode report: {'average_total_reward': np.float32(0.921), 'reward_variance': np.float32(0.030128997), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 60608} @ step loss: {'critic_loss': np.float64(138.69508056640626), 'actor_loss': np.float64(-28.144149017333984), 'alpha_loss': np.float64(-0.14733240455389024), 'alpha': np.float64(1.6574129462242126)}
step: 1840 @ episode report: {'average_total_reward': np.float32(0.854), 'reward_variance': np.float32(0.11556399), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 60928} @ step loss: {'critic_loss': np.float64(137.83646621704102), 'actor_loss': np.float64(-28.20810432434082), 'alpha_loss': np.float64(-0.14977411478757857), 'alpha': np.float64(1.6623814582824707)}
step: 1850 @ episode report: {'average_total_reward': np.float32(0.798), 'reward_variance': np.float32(0.09659599), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 61248} @ step loss: {'critic_loss': np.float64(139.76513214111327), 'actor_loss': np.float64(-28.425614166259766), 'alpha_loss': np.float64(-0.1493145227432251), 'alpha': np.float64(1.6673702120780944)}
step: 1860 @ episode report: {'average_total_reward': np.float32(1.088), 'reward_variance': np.float32(0.14829604), 'max_total_reward': np.float32(1.8000002), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 61568} @ step loss: {'critic_loss': np.float64(137.83050994873048), 'actor_loss': np.float64(-28.465238571166992), 'alpha_loss': np.float64(-0.1488933965563774), 'alpha': np.float64(1.6723494291305543)}
step: 1870 @ episode report: {'average_total_reward': np.float32(0.744), 'reward_variance': np.float32(0.08146402), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 61888} @ step loss: {'critic_loss': np.float64(145.87778015136718), 'actor_loss': np.float64(-28.627957153320313), 'alpha_loss': np.float64(-0.1512425035238266), 'alpha': np.float64(1.6773206830024718)}
step: 1880 @ episode report: {'average_total_reward': np.float32(0.809), 'reward_variance': np.float32(0.11224902), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 62208} @ step loss: {'critic_loss': np.float64(146.01610565185547), 'actor_loss': np.float64(-28.79515609741211), 'alpha_loss': np.float64(-0.15299811363220214), 'alpha': np.float64(1.6823299884796143)}
step: 1890 @ episode report: {'average_total_reward': np.float32(0.632), 'reward_variance': np.float32(0.12701601), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.019999992), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 62528} @ step loss: {'critic_loss': np.float64(147.33870391845704), 'actor_loss': np.float64(-28.874599647521972), 'alpha_loss': np.float64(-0.15298167616128922), 'alpha': np.float64(1.6873660922050475)}
step: 1900 @ episode report: {'average_total_reward': np.float32(0.854), 'reward_variance': np.float32(0.064744), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 62848} @ step loss: {'critic_loss': np.float64(144.319970703125), 'actor_loss': np.float64(-28.930354881286622), 'alpha_loss': np.float64(-0.15585493445396423), 'alpha': np.float64(1.6924309134483337)}
step: 1910 @ episode report: {'average_total_reward': np.float32(0.732), 'reward_variance': np.float32(0.15269598), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 63168} @ step loss: {'critic_loss': np.float64(149.5693588256836), 'actor_loss': np.float64(-29.13532962799072), 'alpha_loss': np.float64(-0.15574804991483687), 'alpha': np.float64(1.6975324630737305)}
step: 1920 @ episode report: {'average_total_reward': np.float32(0.897), 'reward_variance': np.float32(0.16144101), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.019999996), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 63488} @ step loss: {'critic_loss': np.float64(150.85921630859374), 'actor_loss': np.float64(-29.194985580444335), 'alpha_loss': np.float64(-0.1583671510219574), 'alpha': np.float64(1.7026523351669312)}
step: 1930 @ episode report: {'average_total_reward': np.float32(0.93200004), 'reward_variance': np.float32(0.055176), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 63808} @ step loss: {'critic_loss': np.float64(149.36159973144532), 'actor_loss': np.float64(-29.294058418273927), 'alpha_loss': np.float64(-0.15921521931886673), 'alpha': np.float64(1.7078176259994506)}
step: 1940 @ episode report: {'average_total_reward': np.float32(0.98800004), 'reward_variance': np.float32(0.261576), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.01999998), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 64128} @ step loss: {'critic_loss': np.float64(154.24474639892577), 'actor_loss': np.float64(-29.47882843017578), 'alpha_loss': np.float64(-0.16138997972011565), 'alpha': np.float64(1.7130154013633727)}
step: 1950 @ episode report: {'average_total_reward': np.float32(0.91), 'reward_variance': np.float32(0.045980006), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 64448} @ step loss: {'critic_loss': np.float64(157.49248199462892), 'actor_loss': np.float64(-29.570046806335448), 'alpha_loss': np.float64(-0.16345316916704178), 'alpha': np.float64(1.718251609802246)}
step: 1960 @ episode report: {'average_total_reward': np.float32(0.96599996), 'reward_variance': np.float32(0.23526402), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 64768} @ step loss: {'critic_loss': np.float64(155.5111068725586), 'actor_loss': np.float64(-29.676909065246583), 'alpha_loss': np.float64(-0.16618433147668837), 'alpha': np.float64(1.7235431909561156)}
step: 1970 @ episode report: {'average_total_reward': np.float32(1.0209999), 'reward_variance': np.float32(0.095709), 'max_total_reward': np.float32(1.69), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 65088} @ step loss: {'critic_loss': np.float64(160.46180114746093), 'actor_loss': np.float64(-29.718055152893065), 'alpha_loss': np.float64(-0.16694510132074356), 'alpha': np.float64(1.728886568546295)}
step: 1980 @ episode report: {'average_total_reward': np.float32(0.776), 'reward_variance': np.float32(0.16664405), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(2.8), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 65408} @ step loss: {'critic_loss': np.float64(161.3184616088867), 'actor_loss': np.float64(-29.7630334854126), 'alpha_loss': np.float64(-0.17025591135025026), 'alpha': np.float64(1.7342716932296753)}
step: 1990 @ episode report: {'average_total_reward': np.float32(0.96500003), 'reward_variance': np.float32(0.019965012), 'max_total_reward': np.float32(1.2400001), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 65728} @ step loss: {'critic_loss': np.float64(149.53102111816406), 'actor_loss': np.float64(-29.856833267211915), 'alpha_loss': np.float64(-0.17270813882350922), 'alpha': np.float64(1.7397207856178283)}
step: 2000 @ episode report: {'average_total_reward': np.float32(0.91), 'reward_variance': np.float32(0.075020015), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 66048} @ step loss: {'critic_loss': np.float64(154.82371520996094), 'actor_loss': np.float64(-30.08892250061035), 'alpha_loss': np.float64(-0.17435262799263002), 'alpha': np.float64(1.7452386260032653)}
step: 2010 @ episode report: {'average_total_reward': np.float32(0.855), 'reward_variance': np.float32(0.049005), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 66368} @ step loss: {'critic_loss': np.float64(161.68011016845702), 'actor_loss': np.float64(-30.231964302062988), 'alpha_loss': np.float64(-0.17801388800144197), 'alpha': np.float64(1.7507992148399354)}
step: 2020 @ episode report: {'average_total_reward': np.float32(1.0200001), 'reward_variance': np.float32(0.033879995), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 66688} @ step loss: {'critic_loss': np.float64(160.69599151611328), 'actor_loss': np.float64(-30.31950511932373), 'alpha_loss': np.float64(-0.17932431697845458), 'alpha': np.float64(1.7564243793487548)}
step: 2030 @ episode report: {'average_total_reward': np.float32(1.076), 'reward_variance': np.float32(0.057264), 'max_total_reward': np.float32(1.58), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 67008} @ step loss: {'critic_loss': np.float64(159.0797607421875), 'actor_loss': np.float64(-30.495624160766603), 'alpha_loss': np.float64(-0.18141271770000458), 'alpha': np.float64(1.7621010303497315)}
step: 2040 @ episode report: {'average_total_reward': np.float32(0.9), 'reward_variance': np.float32(0.13840005), 'max_total_reward': np.float32(1.8000002), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 67328} @ step loss: {'critic_loss': np.float64(165.43514556884764), 'actor_loss': np.float64(-30.553615951538085), 'alpha_loss': np.float64(-0.18380035310983658), 'alpha': np.float64(1.7678237795829772)}
step: 2050 @ episode report: {'average_total_reward': np.float32(0.965), 'reward_variance': np.float32(0.21974504), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.24000001), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 67648} @ step loss: {'critic_loss': np.float64(164.75371398925782), 'actor_loss': np.float64(-30.669071388244628), 'alpha_loss': np.float64(-0.18486356884241104), 'alpha': np.float64(1.7735915541648866)}
step: 2060 @ episode report: {'average_total_reward': np.float32(0.91), 'reward_variance': np.float32(0.3263), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(-0.09), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 67968} @ step loss: {'critic_loss': np.float64(159.93810119628907), 'actor_loss': np.float64(-30.81290912628174), 'alpha_loss': np.float64(-0.18626998364925385), 'alpha': np.float64(1.7793874740600586)}
step: 2070 @ episode report: {'average_total_reward': np.float32(1.109), 'reward_variance': np.float32(0.20504901), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 68288} @ step loss: {'critic_loss': np.float64(163.3697036743164), 'actor_loss': np.float64(-30.960219192504884), 'alpha_loss': np.float64(-0.1875504732131958), 'alpha': np.float64(1.7852020740509034)}
step: 2080 @ episode report: {'average_total_reward': np.float32(0.83199996), 'reward_variance': np.float32(0.10095601), 'max_total_reward': np.float32(1.13), 'min_total_reward': np.float32(0.019999973), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 68608} @ step loss: {'critic_loss': np.float64(168.13296661376953), 'actor_loss': np.float64(-31.15899066925049), 'alpha_loss': np.float64(-0.18813080489635467), 'alpha': np.float64(1.791040563583374)}
step: 2090 @ episode report: {'average_total_reward': np.float32(0.821), 'reward_variance': np.float32(0.06358902), 'max_total_reward': np.float32(1.1300001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 68928} @ step loss: {'critic_loss': np.float64(174.6752914428711), 'actor_loss': np.float64(-31.216294288635254), 'alpha_loss': np.float64(-0.19028665721416474), 'alpha': np.float64(1.7968923687934875)}
step: 2100 @ episode report: {'average_total_reward': np.float32(1.132), 'reward_variance': np.float32(0.19911602), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 69248} @ step loss: {'critic_loss': np.float64(171.6020980834961), 'actor_loss': np.float64(-31.32303581237793), 'alpha_loss': np.float64(-0.194351826608181), 'alpha': np.float64(1.8027814745903015)}
step: 2110 @ episode report: {'average_total_reward': np.float32(1.01), 'reward_variance': np.float32(0.31640002), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(-0.09000001), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 69568} @ step loss: {'critic_loss': np.float64(175.52672729492187), 'actor_loss': np.float64(-31.407353591918945), 'alpha_loss': np.float64(-0.19578276574611664), 'alpha': np.float64(1.8087393999099732)}
step: 2120 @ episode report: {'average_total_reward': np.float32(1.0540001), 'reward_variance': np.float32(0.147464), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 69888} @ step loss: {'critic_loss': np.float64(172.74212646484375), 'actor_loss': np.float64(-31.579873657226564), 'alpha_loss': np.float64(-0.19924816489219666), 'alpha': np.float64(1.81475510597229)}
step: 2130 @ episode report: {'average_total_reward': np.float32(1.0100001), 'reward_variance': np.float32(0.18944), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.47), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 70208} @ step loss: {'critic_loss': np.float64(178.61688385009765), 'actor_loss': np.float64(-31.58113040924072), 'alpha_loss': np.float64(-0.2026665985584259), 'alpha': np.float64(1.8208382606506348)}
step: 2140 @ episode report: {'average_total_reward': np.float32(0.96599996), 'reward_variance': np.float32(0.13558401), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 70528} @ step loss: {'critic_loss': np.float64(174.272216796875), 'actor_loss': np.float64(-31.745909881591796), 'alpha_loss': np.float64(-0.20329213440418242), 'alpha': np.float64(1.8269791841506957)}
step: 2150 @ episode report: {'average_total_reward': np.float32(0.98599994), 'reward_variance': np.float32(0.10324399), 'max_total_reward': np.float32(1.3499999), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 70848} @ step loss: {'critic_loss': np.float64(186.25642852783204), 'actor_loss': np.float64(-31.913186454772948), 'alpha_loss': np.float64(-0.20520671606063842), 'alpha': np.float64(1.8331602692604065)}
step: 2160 @ episode report: {'average_total_reward': np.float32(1.21), 'reward_variance': np.float32(0.25620005), 'max_total_reward': np.float32(2.0200002), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 71168} @ step loss: {'critic_loss': np.float64(181.91191864013672), 'actor_loss': np.float64(-31.936284637451173), 'alpha_loss': np.float64(-0.2060656175017357), 'alpha': np.float64(1.839358425140381)}
step: 2170 @ episode report: {'average_total_reward': np.float32(0.9639999), 'reward_variance': np.float32(0.11094401), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 71488} @ step loss: {'critic_loss': np.float64(182.5205535888672), 'actor_loss': np.float64(-32.058088874816896), 'alpha_loss': np.float64(-0.20824213027954103), 'alpha': np.float64(1.8455778002738952)}
step: 2180 @ episode report: {'average_total_reward': np.float32(1.32), 'reward_variance': np.float32(0.24366005), 'max_total_reward': np.float32(2.0200002), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 71808} @ step loss: {'critic_loss': np.float64(175.72418365478515), 'actor_loss': np.float64(-32.18983383178711), 'alpha_loss': np.float64(-0.2093738690018654), 'alpha': np.float64(1.851823353767395)}
step: 2190 @ episode report: {'average_total_reward': np.float32(1.0520002), 'reward_variance': np.float32(0.08401601), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 72128} @ step loss: {'critic_loss': np.float64(182.41468811035156), 'actor_loss': np.float64(-32.36238441467285), 'alpha_loss': np.float64(-0.21107293367385865), 'alpha': np.float64(1.8580848693847656)}
step: 2200 @ episode report: {'average_total_reward': np.float32(1.4530001), 'reward_variance': np.float32(0.24232104), 'max_total_reward': np.float32(2.2400002), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 72448} @ step loss: {'critic_loss': np.float64(186.33997650146483), 'actor_loss': np.float64(-32.475960159301756), 'alpha_loss': np.float64(-0.21355337351560594), 'alpha': np.float64(1.864374589920044)}
step: 2210 @ episode report: {'average_total_reward': np.float32(1.054), 'reward_variance': np.float32(0.31534398), 'max_total_reward': np.float32(2.2399998), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 72768} @ step loss: {'critic_loss': np.float64(191.65732116699218), 'actor_loss': np.float64(-32.63157844543457), 'alpha_loss': np.float64(-0.21518722623586656), 'alpha': np.float64(1.8707100033760071)}
step: 2220 @ episode report: {'average_total_reward': np.float32(1.043), 'reward_variance': np.float32(0.04634101), 'max_total_reward': np.float32(1.47), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 73088} @ step loss: {'critic_loss': np.float64(190.10894012451172), 'actor_loss': np.float64(-32.76655197143555), 'alpha_loss': np.float64(-0.21804159283638), 'alpha': np.float64(1.877077615261078)}
step: 2230 @ episode report: {'average_total_reward': np.float32(0.8870001), 'reward_variance': np.float32(0.10970102), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 73408} @ step loss: {'critic_loss': np.float64(193.7309097290039), 'actor_loss': np.float64(-32.83703079223633), 'alpha_loss': np.float64(-0.2197500303387642), 'alpha': np.float64(1.883490836620331)}
step: 2240 @ episode report: {'average_total_reward': np.float32(0.93100005), 'reward_variance': np.float32(0.124529004), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 73728} @ step loss: {'critic_loss': np.float64(188.45473022460936), 'actor_loss': np.float64(-32.88844680786133), 'alpha_loss': np.float64(-0.2231589749455452), 'alpha': np.float64(1.8899511575698853)}
step: 2250 @ episode report: {'average_total_reward': np.float32(1.0440001), 'reward_variance': np.float32(0.18402405), 'max_total_reward': np.float32(1.9100002), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 74048} @ step loss: {'critic_loss': np.float64(194.40485687255858), 'actor_loss': np.float64(-33.016493225097655), 'alpha_loss': np.float64(-0.22558889240026475), 'alpha': np.float64(1.8964614868164062)}
step: 2260 @ episode report: {'average_total_reward': np.float32(0.99799997), 'reward_variance': np.float32(0.040656008), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 74368} @ step loss: {'critic_loss': np.float64(194.74562072753906), 'actor_loss': np.float64(-33.175749969482425), 'alpha_loss': np.float64(-0.22840059846639632), 'alpha': np.float64(1.9030332684516906)}
step: 2270 @ episode report: {'average_total_reward': np.float32(0.96500003), 'reward_variance': np.float32(0.14626503), 'max_total_reward': np.float32(1.69), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 74688} @ step loss: {'critic_loss': np.float64(189.8057067871094), 'actor_loss': np.float64(-33.31275978088379), 'alpha_loss': np.float64(-0.22868766635656357), 'alpha': np.float64(1.9096381187438964)}
step: 2280 @ episode report: {'average_total_reward': np.float32(1.121), 'reward_variance': np.float32(0.15382901), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 75008} @ step loss: {'critic_loss': np.float64(197.08389434814453), 'actor_loss': np.float64(-33.42841987609863), 'alpha_loss': np.float64(-0.23008554577827453), 'alpha': np.float64(1.9162460327148438)}
step: 2290 @ episode report: {'average_total_reward': np.float32(0.998), 'reward_variance': np.float32(0.108656004), 'max_total_reward': np.float32(1.58), 'min_total_reward': np.float32(0.24000002), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 75328} @ step loss: {'critic_loss': np.float64(195.74760894775392), 'actor_loss': np.float64(-33.6068172454834), 'alpha_loss': np.float64(-0.23487127274274827), 'alpha': np.float64(1.9229005217552184)}
step: 2300 @ episode report: {'average_total_reward': np.float32(0.83000004), 'reward_variance': np.float32(0.17062001), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.24000001), 'average_n_step': np.float32(2.7), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 75648} @ step loss: {'critic_loss': np.float64(208.49574127197266), 'actor_loss': np.float64(-33.72942771911621), 'alpha_loss': np.float64(-0.23676928430795668), 'alpha': np.float64(1.9296183824539184)}
step: 2310 @ episode report: {'average_total_reward': np.float32(1.2980001), 'reward_variance': np.float32(0.24185602), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.6900001), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 75968} @ step loss: {'critic_loss': np.float64(204.9604690551758), 'actor_loss': np.float64(-33.77387008666992), 'alpha_loss': np.float64(-0.24168201088905333), 'alpha': np.float64(1.9363885283470155)}
step: 2320 @ episode report: {'average_total_reward': np.float32(1.286), 'reward_variance': np.float32(0.221644), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 76288} @ step loss: {'critic_loss': np.float64(203.60404052734376), 'actor_loss': np.float64(-33.94167137145996), 'alpha_loss': np.float64(-0.2427284836769104), 'alpha': np.float64(1.9432300090789796)}
step: 2330 @ episode report: {'average_total_reward': np.float32(1.231), 'reward_variance': np.float32(0.24930897), 'max_total_reward': np.float32(2.35), 'min_total_reward': np.float32(0.90999997), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 76608} @ step loss: {'critic_loss': np.float64(198.24868469238282), 'actor_loss': np.float64(-34.04447937011719), 'alpha_loss': np.float64(-0.24446312934160233), 'alpha': np.float64(1.9501180171966552)}
step: 2340 @ episode report: {'average_total_reward': np.float32(1.0649999), 'reward_variance': np.float32(0.098744996), 'max_total_reward': np.float32(1.8), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 76928} @ step loss: {'critic_loss': np.float64(201.20856781005858), 'actor_loss': np.float64(-34.14392280578613), 'alpha_loss': np.float64(-0.24804537892341613), 'alpha': np.float64(1.9570362210273742)}
step: 2350 @ episode report: {'average_total_reward': np.float32(0.976), 'reward_variance': np.float32(0.039204), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 77248} @ step loss: {'critic_loss': np.float64(207.4590576171875), 'actor_loss': np.float64(-34.370690536499026), 'alpha_loss': np.float64(-0.24973728656768798), 'alpha': np.float64(1.9639907479286194)}
step: 2360 @ episode report: {'average_total_reward': np.float32(1.042), 'reward_variance': np.float32(0.028556), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 77568} @ step loss: {'critic_loss': np.float64(210.79544677734376), 'actor_loss': np.float64(-34.51827201843262), 'alpha_loss': np.float64(-0.25300168991088867), 'alpha': np.float64(1.9709904789924622)}
step: 2370 @ episode report: {'average_total_reward': np.float32(1.264), 'reward_variance': np.float32(0.35696393), 'max_total_reward': np.float32(2.9099998), 'min_total_reward': np.float32(0.46999994), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 77888} @ step loss: {'critic_loss': np.float64(214.14069519042968), 'actor_loss': np.float64(-34.61179962158203), 'alpha_loss': np.float64(-0.2556731551885605), 'alpha': np.float64(1.9780344128608705)}
step: 2380 @ episode report: {'average_total_reward': np.float32(1.065), 'reward_variance': np.float32(0.088845), 'max_total_reward': np.float32(1.6899999), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 78208} @ step loss: {'critic_loss': np.float64(206.30005950927733), 'actor_loss': np.float64(-34.710239028930665), 'alpha_loss': np.float64(-0.2604465872049332), 'alpha': np.float64(1.9851454734802245)}
step: 2390 @ episode report: {'average_total_reward': np.float32(1.02), 'reward_variance': np.float32(0.27238005), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 78528} @ step loss: {'critic_loss': np.float64(205.59003753662108), 'actor_loss': np.float64(-34.87791290283203), 'alpha_loss': np.float64(-0.26228421926498413), 'alpha': np.float64(1.9923296928405763)}
step: 2400 @ episode report: {'average_total_reward': np.float32(1.174), 'reward_variance': np.float32(0.036784004), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 78848} @ step loss: {'critic_loss': np.float64(214.21880340576172), 'actor_loss': np.float64(-35.081960678100586), 'alpha_loss': np.float64(-0.26409857869148257), 'alpha': np.float64(1.999550986289978)}
step: 2410 @ episode report: {'average_total_reward': np.float32(1.109), 'reward_variance': np.float32(0.09306901), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 79168} @ step loss: {'critic_loss': np.float64(219.60206909179686), 'actor_loss': np.float64(-35.22777633666992), 'alpha_loss': np.float64(-0.26670117378234864), 'alpha': np.float64(2.006800389289856)}
step: 2420 @ episode report: {'average_total_reward': np.float32(1.109), 'reward_variance': np.float32(0.12716903), 'max_total_reward': np.float32(2.0200002), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 79488} @ step loss: {'critic_loss': np.float64(226.37489166259766), 'actor_loss': np.float64(-35.18915939331055), 'alpha_loss': np.float64(-0.26932524144649506), 'alpha': np.float64(2.014083480834961)}
step: 2430 @ episode report: {'average_total_reward': np.float32(0.976), 'reward_variance': np.float32(0.034364004), 'max_total_reward': np.float32(1.24), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 79808} @ step loss: {'critic_loss': np.float64(221.61090393066405), 'actor_loss': np.float64(-35.325857162475586), 'alpha_loss': np.float64(-0.2742575317621231), 'alpha': np.float64(2.0214205741882325)}
step: 2440 @ episode report: {'average_total_reward': np.float32(1.242), 'reward_variance': np.float32(0.21605599), 'max_total_reward': np.float32(2.35), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 80128} @ step loss: {'critic_loss': np.float64(226.2384994506836), 'actor_loss': np.float64(-35.448359680175784), 'alpha_loss': np.float64(-0.2745440423488617), 'alpha': np.float64(2.0288079977035522)}
step: 2450 @ episode report: {'average_total_reward': np.float32(1.187), 'reward_variance': np.float32(0.34120098), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.24000004), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 80448} @ step loss: {'critic_loss': np.float64(224.22996673583984), 'actor_loss': np.float64(-35.62887840270996), 'alpha_loss': np.float64(-0.27617748975753786), 'alpha': np.float64(2.036222815513611)}
step: 2460 @ episode report: {'average_total_reward': np.float32(0.899), 'reward_variance': np.float32(0.16148904), 'max_total_reward': np.float32(1.8000002), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 80768} @ step loss: {'critic_loss': np.float64(218.71249389648438), 'actor_loss': np.float64(-35.725395584106444), 'alpha_loss': np.float64(-0.27663467526435853), 'alpha': np.float64(2.043642592430115)}
step: 2470 @ episode report: {'average_total_reward': np.float32(1.221), 'reward_variance': np.float32(0.29204905), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.47000003), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 81088} @ step loss: {'critic_loss': np.float64(236.22663421630858), 'actor_loss': np.float64(-35.886253356933594), 'alpha_loss': np.float64(-0.278204670548439), 'alpha': np.float64(2.0510622024536134)}
step: 2480 @ episode report: {'average_total_reward': np.float32(1.387), 'reward_variance': np.float32(0.275981), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 81408} @ step loss: {'critic_loss': np.float64(216.3913116455078), 'actor_loss': np.float64(-35.907157516479494), 'alpha_loss': np.float64(-0.28124421536922456), 'alpha': np.float64(2.058499789237976)}
step: 2490 @ episode report: {'average_total_reward': np.float32(1.0649999), 'reward_variance': np.float32(0.086645015), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 81728} @ step loss: {'critic_loss': np.float64(229.54523315429688), 'actor_loss': np.float64(-36.09864463806152), 'alpha_loss': np.float64(-0.2803199619054794), 'alpha': np.float64(2.065948724746704)}
step: 2500 @ episode report: {'average_total_reward': np.float32(0.96599996), 'reward_variance': np.float32(0.167264), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 82048} @ step loss: {'critic_loss': np.float64(236.78141326904296), 'actor_loss': np.float64(-36.30760955810547), 'alpha_loss': np.float64(-0.2849707126617432), 'alpha': np.float64(2.0734067440032957)}
step: 2510 @ episode report: {'average_total_reward': np.float32(1.354), 'reward_variance': np.float32(0.25632405), 'max_total_reward': np.float32(2.0200002), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 82368} @ step loss: {'critic_loss': np.float64(238.97426147460936), 'actor_loss': np.float64(-36.32653656005859), 'alpha_loss': np.float64(-0.2833518207073212), 'alpha': np.float64(2.080883836746216)}
step: 2520 @ episode report: {'average_total_reward': np.float32(1.264), 'reward_variance': np.float32(0.39392406), 'max_total_reward': np.float32(2.2400002), 'min_total_reward': np.float32(0.24000001), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 82688} @ step loss: {'critic_loss': np.float64(229.58831024169922), 'actor_loss': np.float64(-36.47489700317383), 'alpha_loss': np.float64(-0.28753825426101687), 'alpha': np.float64(2.088365888595581)}
step: 2530 @ episode report: {'average_total_reward': np.float32(1.108), 'reward_variance': np.float32(0.157716), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 83008} @ step loss: {'critic_loss': np.float64(237.1926284790039), 'actor_loss': np.float64(-36.59005546569824), 'alpha_loss': np.float64(-0.2896575540304184), 'alpha': np.float64(2.0958781242370605)}
step: 2540 @ episode report: {'average_total_reward': np.float32(1.0090001), 'reward_variance': np.float32(0.15422902), 'max_total_reward': np.float32(1.6900002), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 83328} @ step loss: {'critic_loss': np.float64(246.43222351074218), 'actor_loss': np.float64(-36.78652763366699), 'alpha_loss': np.float64(-0.2898676574230194), 'alpha': np.float64(2.10341899394989)}
step: 2550 @ episode report: {'average_total_reward': np.float32(1.0860001), 'reward_variance': np.float32(0.0125840055), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.9100001), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 83648} @ step loss: {'critic_loss': np.float64(244.1252670288086), 'actor_loss': np.float64(-36.8236083984375), 'alpha_loss': np.float64(-0.29463818669319153), 'alpha': np.float64(2.1109760284423826)}
step: 2560 @ episode report: {'average_total_reward': np.float32(1.0660001), 'reward_variance': np.float32(0.272904), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 83968} @ step loss: {'critic_loss': np.float64(248.53580780029296), 'actor_loss': np.float64(-36.972110748291016), 'alpha_loss': np.float64(-0.294969043135643), 'alpha': np.float64(2.1185702085494995)}
step: 2570 @ episode report: {'average_total_reward': np.float32(0.91), 'reward_variance': np.float32(0.08712001), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.24999999), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 84288} @ step loss: {'critic_loss': np.float64(243.8295654296875), 'actor_loss': np.float64(-37.01236572265625), 'alpha_loss': np.float64(-0.2966896414756775), 'alpha': np.float64(2.126185750961304)}
step: 2580 @ episode report: {'average_total_reward': np.float32(1.253), 'reward_variance': np.float32(0.21754098), 'max_total_reward': np.float32(2.35), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 84608} @ step loss: {'critic_loss': np.float64(247.13408203125), 'actor_loss': np.float64(-37.18670539855957), 'alpha_loss': np.float64(-0.294658237695694), 'alpha': np.float64(2.1337992668151857)}
step: 2590 @ episode report: {'average_total_reward': np.float32(1.01), 'reward_variance': np.float32(0.07482), 'max_total_reward': np.float32(1.58), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 84928} @ step loss: {'critic_loss': np.float64(246.43051147460938), 'actor_loss': np.float64(-37.32104644775391), 'alpha_loss': np.float64(-0.2990116387605667), 'alpha': np.float64(2.1413885831832884)}
step: 2600 @ episode report: {'average_total_reward': np.float32(0.975), 'reward_variance': np.float32(0.08422499), 'max_total_reward': np.float32(1.3499999), 'min_total_reward': np.float32(0.24), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(2.0), 'buffer_size': 85248} @ step loss: {'critic_loss': np.float64(244.8702133178711), 'actor_loss': np.float64(-37.483795928955075), 'alpha_loss': np.float64(-0.2960275888442993), 'alpha': np.float64(2.148998427391052)}
step: 2610 @ episode report: {'average_total_reward': np.float32(1.2310002), 'reward_variance': np.float32(0.063409), 'max_total_reward': np.float32(1.69), 'min_total_reward': np.float32(0.91), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 85568} @ step loss: {'critic_loss': np.float64(247.3622848510742), 'actor_loss': np.float64(-37.58267097473144), 'alpha_loss': np.float64(-0.2973917812108994), 'alpha': np.float64(2.156578850746155)}
step: 2620 @ episode report: {'average_total_reward': np.float32(1.1310002), 'reward_variance': np.float32(0.14476903), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 85888} @ step loss: {'critic_loss': np.float64(247.66893615722657), 'actor_loss': np.float64(-37.75727005004883), 'alpha_loss': np.float64(-0.29793859720230104), 'alpha': np.float64(2.1641414165496826)}
step: 2630 @ episode report: {'average_total_reward': np.float32(1.32), 'reward_variance': np.float32(0.32924), 'max_total_reward': np.float32(2.35), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 86208} @ step loss: {'critic_loss': np.float64(251.9406494140625), 'actor_loss': np.float64(-37.8143611907959), 'alpha_loss': np.float64(-0.29787994027137754), 'alpha': np.float64(2.1716867446899415)}
step: 2640 @ episode report: {'average_total_reward': np.float32(1.1860001), 'reward_variance': np.float32(0.098844014), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 86528} @ step loss: {'critic_loss': np.float64(253.58433685302734), 'actor_loss': np.float64(-38.000193405151364), 'alpha_loss': np.float64(-0.2979830354452133), 'alpha': np.float64(2.1792112588882446)}
step: 2650 @ episode report: {'average_total_reward': np.float32(1.1639999), 'reward_variance': np.float32(0.19366403), 'max_total_reward': np.float32(2.3500001), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 86848} @ step loss: {'critic_loss': np.float64(255.559912109375), 'actor_loss': np.float64(-38.19823112487793), 'alpha_loss': np.float64(-0.29813745319843293), 'alpha': np.float64(2.186733102798462)}
step: 2660 @ episode report: {'average_total_reward': np.float32(1.419), 'reward_variance': np.float32(0.21504898), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 87168} @ step loss: {'critic_loss': np.float64(259.04624328613284), 'actor_loss': np.float64(-38.35005073547363), 'alpha_loss': np.float64(-0.30155288577079775), 'alpha': np.float64(2.19424684047699)}
step: 2670 @ episode report: {'average_total_reward': np.float32(1.4979999), 'reward_variance': np.float32(0.23455599), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.5), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 87488} @ step loss: {'critic_loss': np.float64(250.78821563720703), 'actor_loss': np.float64(-38.4906063079834), 'alpha_loss': np.float64(-0.3025243729352951), 'alpha': np.float64(2.201781916618347)}
step: 2680 @ episode report: {'average_total_reward': np.float32(1.319), 'reward_variance': np.float32(0.22136903), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 87808} @ step loss: {'critic_loss': np.float64(264.79579162597656), 'actor_loss': np.float64(-38.695076370239256), 'alpha_loss': np.float64(-0.30768565833568573), 'alpha': np.float64(2.2093511819839478)}
step: 2690 @ episode report: {'average_total_reward': np.float32(1.22), 'reward_variance': np.float32(0.40598002), 'max_total_reward': np.float32(2.46), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 88128} @ step loss: {'critic_loss': np.float64(254.14580993652345), 'actor_loss': np.float64(-38.78041496276855), 'alpha_loss': np.float64(-0.30968937277793884), 'alpha': np.float64(2.21698796749115)}
step: 2700 @ episode report: {'average_total_reward': np.float32(1.5200001), 'reward_variance': np.float32(0.27156), 'max_total_reward': np.float32(2.3500001), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.5), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 88448} @ step loss: {'critic_loss': np.float64(257.98881072998046), 'actor_loss': np.float64(-38.89822769165039), 'alpha_loss': np.float64(-0.30986314415931704), 'alpha': np.float64(2.2246665000915526)}
step: 2710 @ episode report: {'average_total_reward': np.float32(1.098), 'reward_variance': np.float32(0.09105601), 'max_total_reward': np.float32(1.8000001), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 88768} @ step loss: {'critic_loss': np.float64(262.8695465087891), 'actor_loss': np.float64(-39.0879451751709), 'alpha_loss': np.float64(-0.3132438838481903), 'alpha': np.float64(2.2323626279830933)}
step: 2720 @ episode report: {'average_total_reward': np.float32(1.1970001), 'reward_variance': np.float32(0.3820811), 'max_total_reward': np.float32(2.3500001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 89088} @ step loss: {'critic_loss': np.float64(269.7432037353516), 'actor_loss': np.float64(-39.25030403137207), 'alpha_loss': np.float64(-0.31485881209373473), 'alpha': np.float64(2.240083169937134)}
step: 2730 @ episode report: {'average_total_reward': np.float32(1.109), 'reward_variance': np.float32(0.100329), 'max_total_reward': np.float32(1.91), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 89408} @ step loss: {'critic_loss': np.float64(271.29835052490233), 'actor_loss': np.float64(-39.41164054870605), 'alpha_loss': np.float64(-0.31876646876335146), 'alpha': np.float64(2.2478485107421875)}
step: 2740 @ episode report: {'average_total_reward': np.float32(1.131), 'reward_variance': np.float32(0.10340901), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 89728} @ step loss: {'critic_loss': np.float64(267.41755828857424), 'actor_loss': np.float64(-39.59281616210937), 'alpha_loss': np.float64(-0.32225348353385924), 'alpha': np.float64(2.2556613206863405)}
step: 2750 @ episode report: {'average_total_reward': np.float32(1.02), 'reward_variance': np.float32(0.048400007), 'max_total_reward': np.float32(1.35), 'min_total_reward': np.float32(0.5799999), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 90048} @ step loss: {'critic_loss': np.float64(273.4656036376953), 'actor_loss': np.float64(-39.69021873474121), 'alpha_loss': np.float64(-0.3235677003860474), 'alpha': np.float64(2.2635402202606203)}
step: 2760 @ episode report: {'average_total_reward': np.float32(1.2320001), 'reward_variance': np.float32(0.28365603), 'max_total_reward': np.float32(2.46), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 90368} @ step loss: {'critic_loss': np.float64(278.3551300048828), 'actor_loss': np.float64(-39.88755416870117), 'alpha_loss': np.float64(-0.32716465294361113), 'alpha': np.float64(2.2714614629745484)}
step: 2770 @ episode report: {'average_total_reward': np.float32(1.0530001), 'reward_variance': np.float32(0.034001), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 90688} @ step loss: {'critic_loss': np.float64(275.60624237060546), 'actor_loss': np.float64(-39.9906566619873), 'alpha_loss': np.float64(-0.3289354294538498), 'alpha': np.float64(2.2794167518615724)}
step: 2780 @ episode report: {'average_total_reward': np.float32(1.042), 'reward_variance': np.float32(0.038236), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 91008} @ step loss: {'critic_loss': np.float64(300.4567901611328), 'actor_loss': np.float64(-40.138278579711915), 'alpha_loss': np.float64(-0.33475908935070037), 'alpha': np.float64(2.287426066398621)}
step: 2790 @ episode report: {'average_total_reward': np.float32(0.98600006), 'reward_variance': np.float32(0.354504), 'max_total_reward': np.float32(2.46), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(2.9), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 91328} @ step loss: {'critic_loss': np.float64(283.9572235107422), 'actor_loss': np.float64(-40.23610420227051), 'alpha_loss': np.float64(-0.33304785192012787), 'alpha': np.float64(2.2954965353012087)}
step: 2800 @ episode report: {'average_total_reward': np.float32(1.3310001), 'reward_variance': np.float32(0.29888904), 'max_total_reward': np.float32(2.5800002), 'min_total_reward': np.float32(0.68999994), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 91648} @ step loss: {'critic_loss': np.float64(286.3293884277344), 'actor_loss': np.float64(-40.31567497253418), 'alpha_loss': np.float64(-0.3344124734401703), 'alpha': np.float64(2.303558111190796)}
step: 2810 @ episode report: {'average_total_reward': np.float32(1.2320001), 'reward_variance': np.float32(0.40577602), 'max_total_reward': np.float32(2.8000002), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(5.0), 'min_n_step': np.float32(3.0), 'buffer_size': 91968} @ step loss: {'critic_loss': np.float64(292.40029296875), 'actor_loss': np.float64(-40.57010269165039), 'alpha_loss': np.float64(-0.3348129570484161), 'alpha': np.float64(2.3116301774978636)}
step: 2820 @ episode report: {'average_total_reward': np.float32(1.319), 'reward_variance': np.float32(0.07968902), 'max_total_reward': np.float32(1.9100002), 'min_total_reward': np.float32(1.02), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 92288} @ step loss: {'critic_loss': np.float64(293.606591796875), 'actor_loss': np.float64(-40.72115592956543), 'alpha_loss': np.float64(-0.3348111748695374), 'alpha': np.float64(2.3196954011917112)}
step: 2830 @ episode report: {'average_total_reward': np.float32(1.3420001), 'reward_variance': np.float32(0.20555604), 'max_total_reward': np.float32(2.2400002), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 92608} @ step loss: {'critic_loss': np.float64(294.30176544189453), 'actor_loss': np.float64(-40.9035701751709), 'alpha_loss': np.float64(-0.337977808713913), 'alpha': np.float64(2.327749466896057)}
step: 2840 @ episode report: {'average_total_reward': np.float32(1.131), 'reward_variance': np.float32(0.08844903), 'max_total_reward': np.float32(1.8000002), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 92928} @ step loss: {'critic_loss': np.float64(304.4434814453125), 'actor_loss': np.float64(-40.97672309875488), 'alpha_loss': np.float64(-0.33664734959602355), 'alpha': np.float64(2.335816526412964)}
step: 2850 @ episode report: {'average_total_reward': np.float32(1.064), 'reward_variance': np.float32(0.21478398), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.13), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 93248} @ step loss: {'critic_loss': np.float64(296.9842987060547), 'actor_loss': np.float64(-41.09799461364746), 'alpha_loss': np.float64(-0.34038553237915037), 'alpha': np.float64(2.343882846832275)}
step: 2860 @ episode report: {'average_total_reward': np.float32(1.0530001), 'reward_variance': np.float32(0.058201008), 'max_total_reward': np.float32(1.3500001), 'min_total_reward': np.float32(0.5799999), 'average_n_step': np.float32(3.0), 'max_n_step': np.float32(3.0), 'min_n_step': np.float32(3.0), 'buffer_size': 93568} @ step loss: {'critic_loss': np.float64(301.1740447998047), 'actor_loss': np.float64(-41.16494445800781), 'alpha_loss': np.float64(-0.34489025771617887), 'alpha': np.float64(2.352000021934509)}
step: 2870 @ episode report: {'average_total_reward': np.float32(1.12), 'reward_variance': np.float32(0.109359995), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.80000013), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 93888} @ step loss: {'critic_loss': np.float64(289.9905609130859), 'actor_loss': np.float64(-41.3611499786377), 'alpha_loss': np.float64(-0.3465519666671753), 'alpha': np.float64(2.360173726081848)}
step: 2880 @ episode report: {'average_total_reward': np.float32(1.3540001), 'reward_variance': np.float32(0.23894405), 'max_total_reward': np.float32(2.2400002), 'min_total_reward': np.float32(0.58), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 94208} @ step loss: {'critic_loss': np.float64(299.0864013671875), 'actor_loss': np.float64(-41.52392463684082), 'alpha_loss': np.float64(-0.3462549924850464), 'alpha': np.float64(2.3683763980865478)}
step: 2890 @ episode report: {'average_total_reward': np.float32(1.0320001), 'reward_variance': np.float32(0.19445603), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.47000003), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 94528} @ step loss: {'critic_loss': np.float64(312.52858276367186), 'actor_loss': np.float64(-41.79540023803711), 'alpha_loss': np.float64(-0.3475708574056625), 'alpha': np.float64(2.3765772104263307)}
step: 2900 @ episode report: {'average_total_reward': np.float32(1.3859999), 'reward_variance': np.float32(0.43666404), 'max_total_reward': np.float32(2.3500001), 'min_total_reward': np.float32(0.12999998), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 94848} @ step loss: {'critic_loss': np.float64(314.5455718994141), 'actor_loss': np.float64(-41.82662582397461), 'alpha_loss': np.float64(-0.3505731523036957), 'alpha': np.float64(2.384789967536926)}
step: 2910 @ episode report: {'average_total_reward': np.float32(1.2520001), 'reward_variance': np.float32(0.11415602), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.90999997), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 95168} @ step loss: {'critic_loss': np.float64(310.5922393798828), 'actor_loss': np.float64(-42.02680892944336), 'alpha_loss': np.float64(-0.3539100557565689), 'alpha': np.float64(2.393042778968811)}
step: 2920 @ episode report: {'average_total_reward': np.float32(1.264), 'reward_variance': np.float32(0.25444403), 'max_total_reward': np.float32(2.0200002), 'min_total_reward': np.float32(0.23999998), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 95488} @ step loss: {'critic_loss': np.float64(313.6544525146484), 'actor_loss': np.float64(-42.11356544494629), 'alpha_loss': np.float64(-0.3588852137327194), 'alpha': np.float64(2.4013527154922487)}
step: 2930 @ episode report: {'average_total_reward': np.float32(1.2980001), 'reward_variance': np.float32(0.18553601), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 95808} @ step loss: {'critic_loss': np.float64(311.4602935791016), 'actor_loss': np.float64(-42.25363388061523), 'alpha_loss': np.float64(-0.3622678965330124), 'alpha': np.float64(2.4097415685653685)}
step: 2940 @ episode report: {'average_total_reward': np.float32(1.143), 'reward_variance': np.float32(0.14912103), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.69000006), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 96128} @ step loss: {'critic_loss': np.float64(318.78322448730466), 'actor_loss': np.float64(-42.46334648132324), 'alpha_loss': np.float64(-0.3630755007266998), 'alpha': np.float64(2.4181931257247924)}
step: 2950 @ episode report: {'average_total_reward': np.float32(1.3750001), 'reward_variance': np.float32(0.34568498), 'max_total_reward': np.float32(2.46), 'min_total_reward': np.float32(0.68999994), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 96448} @ step loss: {'critic_loss': np.float64(316.96513671875), 'actor_loss': np.float64(-42.620059204101565), 'alpha_loss': np.float64(-0.3651384174823761), 'alpha': np.float64(2.426660895347595)}
step: 2960 @ episode report: {'average_total_reward': np.float32(1.252), 'reward_variance': np.float32(0.26047602), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.23999996), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 96768} @ step loss: {'critic_loss': np.float64(318.0441375732422), 'actor_loss': np.float64(-42.77376518249512), 'alpha_loss': np.float64(-0.3674459755420685), 'alpha': np.float64(2.4351537466049193)}
step: 2970 @ episode report: {'average_total_reward': np.float32(1.3640001), 'reward_variance': np.float32(0.13722405), 'max_total_reward': np.float32(2.0200002), 'min_total_reward': np.float32(0.9100001), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 97088} @ step loss: {'critic_loss': np.float64(323.8520568847656), 'actor_loss': np.float64(-42.96796417236328), 'alpha_loss': np.float64(-0.36809608340263367), 'alpha': np.float64(2.443673276901245)}
step: 2980 @ episode report: {'average_total_reward': np.float32(1.376), 'reward_variance': np.float32(0.12872405), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(1.02), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 97408} @ step loss: {'critic_loss': np.float64(310.1011016845703), 'actor_loss': np.float64(-43.093614959716795), 'alpha_loss': np.float64(-0.37233151495456696), 'alpha': np.float64(2.4522109270095824)}
step: 2990 @ episode report: {'average_total_reward': np.float32(1.254), 'reward_variance': np.float32(0.21290405), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.68999994), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 97728} @ step loss: {'critic_loss': np.float64(330.60057678222654), 'actor_loss': np.float64(-43.35140190124512), 'alpha_loss': np.float64(-0.37360591292381284), 'alpha': np.float64(2.460789132118225)}
step: 3000 @ episode report: {'average_total_reward': np.float32(1.164), 'reward_variance': np.float32(0.095984004), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.8000001), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 98048} @ step loss: {'critic_loss': np.float64(339.85967407226565), 'actor_loss': np.float64(-43.41954231262207), 'alpha_loss': np.float64(-0.3771538883447647), 'alpha': np.float64(2.4694142580032348)}
step: 3010 @ episode report: {'average_total_reward': np.float32(1.2409999), 'reward_variance': np.float32(0.13728903), 'max_total_reward': np.float32(2.1300004), 'min_total_reward': np.float32(0.58000004), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 98368} @ step loss: {'critic_loss': np.float64(337.7268585205078), 'actor_loss': np.float64(-43.53003120422363), 'alpha_loss': np.float64(-0.38066767156124115), 'alpha': np.float64(2.4780853986740112)}
step: 3020 @ episode report: {'average_total_reward': np.float32(1.419), 'reward_variance': np.float32(0.27114898), 'max_total_reward': np.float32(2.35), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 98688} @ step loss: {'critic_loss': np.float64(337.14490966796876), 'actor_loss': np.float64(-43.73644676208496), 'alpha_loss': np.float64(-0.3843547165393829), 'alpha': np.float64(2.486808109283447)}
step: 3030 @ episode report: {'average_total_reward': np.float32(1.3199999), 'reward_variance': np.float32(0.21923998), 'max_total_reward': np.float32(2.2399998), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 99008} @ step loss: {'critic_loss': np.float64(337.2691925048828), 'actor_loss': np.float64(-43.84638442993164), 'alpha_loss': np.float64(-0.38592658638954164), 'alpha': np.float64(2.4955821514129637)}
step: 3040 @ episode report: {'average_total_reward': np.float32(1.33), 'reward_variance': np.float32(0.20136002), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.90999997), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 99328} @ step loss: {'critic_loss': np.float64(342.53476867675784), 'actor_loss': np.float64(-44.01649894714355), 'alpha_loss': np.float64(-0.38947378396987914), 'alpha': np.float64(2.50439989566803)}
step: 3050 @ episode report: {'average_total_reward': np.float32(1.0979999), 'reward_variance': np.float32(0.30557606), 'max_total_reward': np.float32(2.02), 'min_total_reward': np.float32(0.13000001), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(2.0), 'buffer_size': 99648} @ step loss: {'critic_loss': np.float64(334.82916259765625), 'actor_loss': np.float64(-44.21929740905762), 'alpha_loss': np.float64(-0.39229587018489837), 'alpha': np.float64(2.5132596254348756)}
step: 3060 @ episode report: {'average_total_reward': np.float32(1.254), 'reward_variance': np.float32(0.18386404), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.8), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 99968} @ step loss: {'critic_loss': np.float64(351.77765197753905), 'actor_loss': np.float64(-44.379805374145505), 'alpha_loss': np.float64(-0.3955136716365814), 'alpha': np.float64(2.522162914276123)}
step: 3070 @ episode report: {'average_total_reward': np.float32(1.609), 'reward_variance': np.float32(0.16078901), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(1.0200001), 'average_n_step': np.float32(3.6), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(346.9568756103516), 'actor_loss': np.float64(-44.63478393554688), 'alpha_loss': np.float64(-0.3976203680038452), 'alpha': np.float64(2.5311206340789796)}
step: 3080 @ episode report: {'average_total_reward': np.float32(1.12), 'reward_variance': np.float32(0.09946002), 'max_total_reward': np.float32(1.9100001), 'min_total_reward': np.float32(0.69), 'average_n_step': np.float32(3.1), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(342.5968902587891), 'actor_loss': np.float64(-44.797346115112305), 'alpha_loss': np.float64(-0.40182303786277773), 'alpha': np.float64(2.5401171684265136)}
step: 3090 @ episode report: {'average_total_reward': np.float32(1.2090001), 'reward_variance': np.float32(0.21894903), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.68999994), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(349.8076904296875), 'actor_loss': np.float64(-44.91528434753418), 'alpha_loss': np.float64(-0.40245825350284575), 'alpha': np.float64(2.5491519212722777)}
step: 3100 @ episode report: {'average_total_reward': np.float32(1.275), 'reward_variance': np.float32(0.17512499), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.9100001), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(345.71171875), 'actor_loss': np.float64(-45.16122207641602), 'alpha_loss': np.float64(-0.4069481760263443), 'alpha': np.float64(2.558223342895508)}
step: 3110 @ episode report: {'average_total_reward': np.float32(1.3199999), 'reward_variance': np.float32(0.21682003), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.68999994), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(359.5759979248047), 'actor_loss': np.float64(-45.40873374938965), 'alpha_loss': np.float64(-0.41185122132301333), 'alpha': np.float64(2.5673574924468996)}
step: 3120 @ episode report: {'average_total_reward': np.float32(1.209), 'reward_variance': np.float32(0.21652904), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.68999994), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(368.8643096923828), 'actor_loss': np.float64(-45.59821472167969), 'alpha_loss': np.float64(-0.4159181773662567), 'alpha': np.float64(2.5765661239624023)}
step: 3130 @ episode report: {'average_total_reward': np.float32(1.3630002), 'reward_variance': np.float32(0.107541025), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(1.02), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(368.16371459960936), 'actor_loss': np.float64(-45.705793380737305), 'alpha_loss': np.float64(-0.4193769097328186), 'alpha': np.float64(2.585835909843445)}
step: 3140 @ episode report: {'average_total_reward': np.float32(1.308), 'reward_variance': np.float32(0.15093602), 'max_total_reward': np.float32(2.0200002), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.2), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(361.4144287109375), 'actor_loss': np.float64(-45.7663215637207), 'alpha_loss': np.float64(-0.4248346209526062), 'alpha': np.float64(2.5951741456985475)}
step: 3150 @ episode report: {'average_total_reward': np.float32(1.409), 'reward_variance': np.float32(0.36670905), 'max_total_reward': np.float32(2.13), 'min_total_reward': np.float32(0.46999997), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(377.61943969726565), 'actor_loss': np.float64(-46.11431732177734), 'alpha_loss': np.float64(-0.4295605421066284), 'alpha': np.float64(2.6045882225036623)}
step: 3160 @ episode report: {'average_total_reward': np.float32(1.442), 'reward_variance': np.float32(0.26063603), 'max_total_reward': np.float32(2.24), 'min_total_reward': np.float32(0.79999995), 'average_n_step': np.float32(3.4), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(361.78273620605466), 'actor_loss': np.float64(-46.18105621337891), 'alpha_loss': np.float64(-0.4285913437604904), 'alpha': np.float64(2.6140692234039307)}
step: 3170 @ episode report: {'average_total_reward': np.float32(1.441), 'reward_variance': np.float32(0.294689), 'max_total_reward': np.float32(2.46), 'min_total_reward': np.float32(0.9100001), 'average_n_step': np.float32(3.3), 'max_n_step': np.float32(4.0), 'min_n_step': np.float32(3.0), 'buffer_size': 100000} @ step loss: {'critic_loss': np.float64(375.2852020263672), 'actor_loss': np.float64(-46.41700439453125), 'alpha_loss': np.float64(-0.4344924181699753), 'alpha': np.float64(2.6235698223114015)}
step: 0 @ episode report: {'average_total_reward': np.float64(0.0), 'reward_variance': np.float64(0.0), 'max_total_reward': np.float64(0.0), 'min_total_reward': np.float64(0.0), 'average_n_step': np.float64(0.0), 'max_n_step': np.float64(0.0), 'min_n_step': np.float64(0.0), 'buffer_size': 2048} @ step loss: {'critic_loss': np.float64(34.58826446533203), 'actor_loss': np.float64(-7.878915786743164), 'alpha_loss': np.float64(0.0), 'alpha': np.float64(0.9997000694274902)}
